{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import operator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mos/Dropbox/memeticscience/typealyzer-dataset/notebooks/jungian_classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle-file used below is available [via Open Science Framework](https://osf.io/gyrc7/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickle_path = \"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>is_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual actual_temp  is_s\n",
       "1    INFJ          nf     0\n",
       "2    INFP          nf     0\n",
       "3    INTP          nt     0\n",
       "5    ENFJ          nf     0\n",
       "10   INFP          nf     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata = pd.read_pickle(df_pickle_path)\n",
    "indata[[\"actual\",\"actual_temp\",\"is_s\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tumblr       21938\n",
       "blogspot       513\n",
       "wordpress      468\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata.domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    22588\n",
       "fr       50\n",
       "da       34\n",
       "de       25\n",
       "no       23\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata.lang.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out English texts only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22919"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = indata[indata.lang == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22588"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add columns percieving and judging for evaluation of s/n and t/f classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata[\"perc_func\"] = indata.actual_temp.str.extract(\"(\\w)\\w\", expand=False)\n",
    "indata[\"judg_func\"] = indata.actual_temp.str.extract(\"\\w(\\w)\", expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indata[pd.isnull(indata[\"tokens\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>typealyzer</th>\n",
       "      <th>actual</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>sntf_s</th>\n",
       "      <th>sntf_n</th>\n",
       "      <th>sntf_t</th>\n",
       "      <th>sntf_f</th>\n",
       "      <th>...</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>they</th>\n",
       "      <th>incl</th>\n",
       "      <th>money</th>\n",
       "      <th>feel</th>\n",
       "      <th>we</th>\n",
       "      <th>hear</th>\n",
       "      <th>perc_func</th>\n",
       "      <th>judg_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url, typealyzer, actual, e, s, t, sntf_s, sntf_n, sntf_t, sntf_f, date, text, tokens, domain, lang, datetime, func, att, funcatt, actual_temp, is_e, is_i, is_f, is_n, is_s, is_t, is_fe, is_fi, is_ne, is_ni, is_se, is_si, is_te, is_ti, is_enfj, is_enfp, is_entj, is_entp, is_esfj, is_esfp, is_estj, is_estp, is_unknown, is_infj, is_infp, is_intj, is_intp, is_isfj, is_isfp, is_istj, is_istp, negate, ppron, nonfl, i, relativ, percept, quant, affect, shehe, achieve, bio, leisure, conj, motion, posemo, adverb, home, future, negemo, number, inhib, humans, pronoun, excl, space, tentat, see, past, anx, family, present, health, verb, certain, anger, preps, swear, ingest, discrep, friend, relig, time, cause, article, body, social, assent, work, sexual, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 117 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata[pd.isnull(indata[\"tokens\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect original data function distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': 488.2908894968084,\n",
       " 'n': 511.4496560721063,\n",
       " 's': 457.63189127105665,\n",
       " 't': 511.27211970074814}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_series = indata[indata.perc_func == \"s\"][\"tokens\"]\n",
    "n_series = indata[indata.perc_func == \"n\"][\"tokens\"]\n",
    "t_series = indata[indata.judg_func == \"t\"][\"tokens\"]\n",
    "f_series = indata[indata.judg_func == \"f\"][\"tokens\"]\n",
    "\n",
    "avg_tkns = {\n",
    "    \"s\":s_series.mean(),\n",
    "    \"n\":n_series.mean(),\n",
    "    \"t\":t_series.mean(),\n",
    "    \"f\":f_series.mean()\n",
    "}\n",
    "avg_tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    16864\n",
       "s     5224\n",
       "Name: perc_func, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata.perc_func.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    12063\n",
       "t    10025\n",
       "Name: judg_func, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata.judg_func.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample equal size text chunks for training and evaluation data\n",
    "See: [Pandas sample()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percieving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 5224 cases in the smallest class s \n",
    "perc_samples = pd.concat([\n",
    "            indata[indata.perc_func == \"s\"].sample(3000, random_state=123456)[[\"text\",\"tokens\",\"perc_func\",\"judg_func\",\"actual_temp\"]],\n",
    "            indata[indata.perc_func == \"n\"].sample(3000, random_state=123456)[[\"text\",\"tokens\",\"perc_func\",\"judg_func\",\"actual_temp\"]]\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s    3000\n",
       "n    3000\n",
       "Name: perc_func, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_samples.perc_func.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    3363\n",
       "t    2637\n",
       "Name: judg_func, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_samples.judg_func.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_samples.to_pickle(\"jung_percieving_functions_samples_blogs_totn6000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_samples = pd.read_pickle(\"jung_percieving_functions_samples_blogs_totn6000.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 10025 cases in the smallest class t\n",
    "judg_samples = pd.concat([\n",
    "            indata[indata.judg_func == \"t\"].sample(3000, random_state=123456)[[\"text\",\"tokens\",\"perc_func\",\"judg_func\",\"actual_temp\"]],\n",
    "            indata[indata.judg_func == \"f\"].sample(3000, random_state=123456)[[\"text\",\"tokens\",\"perc_func\",\"judg_func\",\"actual_temp\"]]\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(judg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    3000\n",
       "t    3000\n",
       "Name: judg_func, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judg_samples.judg_func.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    4598\n",
       "s    1402\n",
       "Name: perc_func, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judg_samples.perc_func.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "judg_samples.to_pickle(\"jung_judging_functions_samples_blogs_totn6000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "judg_samples = pd.read_pickle(\"jung_judging_functions_samples_blogs_totn6000.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split percieving samples into train and eval subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>perc_func</th>\n",
       "      <th>judg_func</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>perc_training_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...</td>\n",
       "      <td>386</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>Log in | Tumblr Sign up Terms Privacy Posted b...</td>\n",
       "      <td>52</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>st</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>a thing of blood © hi im logan and i love the ...</td>\n",
       "      <td>440</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tokens perc_func  \\\n",
       "8623   Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...     386         s   \n",
       "11987  Log in | Tumblr Sign up Terms Privacy Posted b...      52         s   \n",
       "5340   a thing of blood © hi im logan and i love the ...     440         s   \n",
       "\n",
       "      judg_func actual_temp  perc_training_set  \n",
       "8623          f          sf                  0  \n",
       "11987         t          st                  0  \n",
       "5340          f          sf                  0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare column to keep track of what's been used for training\n",
    "zeros = np.zeros(len(perc_samples))\n",
    "perc_samples[\"perc_training_set\"] = zeros\n",
    "perc_samples[\"perc_training_set\"] = perc_samples.perc_training_set.astype(\"int\")\n",
    "perc_samples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>perc_func</th>\n",
       "      <th>judg_func</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>perc_training_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...</td>\n",
       "      <td>386</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>Log in | Tumblr Sign up Terms Privacy Posted b...</td>\n",
       "      <td>52</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>st</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>a thing of blood © hi im logan and i love the ...</td>\n",
       "      <td>440</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>sf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tokens perc_func  \\\n",
       "8623   Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...     386         s   \n",
       "11987  Log in | Tumblr Sign up Terms Privacy Posted b...      52         s   \n",
       "5340   a thing of blood © hi im logan and i love the ...     440         s   \n",
       "\n",
       "      judg_func actual_temp  perc_training_set  \n",
       "8623          f          sf                  0  \n",
       "11987         t          st                  1  \n",
       "5340          f          sf                  1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_traing_set_size = 2100 # e.g. 2100 is 70% of 3000 samples\n",
    "perc_s_train = perc_samples[perc_samples.perc_func == \"s\"].sample(sn_traing_set_size).index\n",
    "perc_n_train = perc_samples[perc_samples.perc_func == \"n\"].sample(sn_traing_set_size).index\n",
    "\n",
    "perc_train = perc_s_train.union(perc_n_train)\n",
    "\n",
    "perc_samples.loc[perc_train, \"perc_training_set\"] = 1\n",
    "perc_samples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perc_samples[perc_samples.perc_training_set == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>perc_func</th>\n",
       "      <th>judg_func</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>perc_training_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...</td>\n",
       "      <td>386</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20508</th>\n",
       "      <td>void of lights void of lights Search Ask me an...</td>\n",
       "      <td>1922</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>st</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>*tamp tamp* *tamp tamp* Index : Ask : submit :...</td>\n",
       "      <td>543</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>st</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tokens perc_func  \\\n",
       "8623   Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...     386         s   \n",
       "20508  void of lights void of lights Search Ask me an...    1922         s   \n",
       "4604   *tamp tamp* *tamp tamp* Index : Ask : submit :...     543         s   \n",
       "\n",
       "      judg_func actual_temp  perc_training_set  \n",
       "8623          f          sf                  0  \n",
       "20508         t          st                  0  \n",
       "4604          t          st                  0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate evaluation DataFrame\n",
    "perc_eval_set = perc_samples[perc_samples.perc_training_set == 0]\n",
    "perc_eval_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perc_eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split judging samples into train and eval subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>perc_func</th>\n",
       "      <th>judg_func</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>judg_training_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22981</th>\n",
       "      <td>it is what it is About Name: Heidi Age:16 Wher...</td>\n",
       "      <td>565</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>st</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24378</th>\n",
       "      <td>https://www.tumblr.com/themes/by/leentheme htt...</td>\n",
       "      <td>582</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>nt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>three things cannot be long hidden © three thi...</td>\n",
       "      <td>516</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>nt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tokens perc_func  \\\n",
       "22981  it is what it is About Name: Heidi Age:16 Wher...     565         s   \n",
       "24378  https://www.tumblr.com/themes/by/leentheme htt...     582         n   \n",
       "5187   three things cannot be long hidden © three thi...     516         n   \n",
       "\n",
       "      judg_func actual_temp  judg_training_set  \n",
       "22981         t          st                  0  \n",
       "24378         t          nt                  0  \n",
       "5187          t          nt                  0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare column to keep track of what's been used for training\n",
    "zeros = np.zeros(len(judg_samples))\n",
    "judg_samples[\"judg_training_set\"] = zeros\n",
    "judg_samples[\"judg_training_set\"] = judg_samples.judg_training_set.astype(\"int\")\n",
    "judg_samples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>perc_func</th>\n",
       "      <th>judg_func</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>judg_training_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22981</th>\n",
       "      <td>it is what it is About Name: Heidi Age:16 Wher...</td>\n",
       "      <td>565</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>st</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24378</th>\n",
       "      <td>https://www.tumblr.com/themes/by/leentheme htt...</td>\n",
       "      <td>582</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>nt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>three things cannot be long hidden © three thi...</td>\n",
       "      <td>516</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>nt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tokens perc_func  \\\n",
       "22981  it is what it is About Name: Heidi Age:16 Wher...     565         s   \n",
       "24378  https://www.tumblr.com/themes/by/leentheme htt...     582         n   \n",
       "5187   three things cannot be long hidden © three thi...     516         n   \n",
       "\n",
       "      judg_func actual_temp  judg_training_set  \n",
       "22981         t          st                  0  \n",
       "24378         t          nt                  0  \n",
       "5187          t          nt                  0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate evaluation DataFrame\n",
    "judg_eval_set = judg_samples[judg_samples.judg_training_set == 0]\n",
    "judg_eval_set.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify percieving function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_jung_percieving_function_of_text(text):\n",
    "    \"\"\"Does what it says, pretty much.\"\"\"\n",
    "    header = {\"Content-Type\": \"application/json\",\n",
    "             \"Authorization\": \"Token \" + os.environ[\"UCLASSIFY_READ\"]}\n",
    "    data = {\"texts\":[text]} # send a one-item list for now, since we don't have a feel for sizes\n",
    "    result = requests.post(\"https://api.uclassify.com/v1/prfekt/jungian-cognitive-function-sensing-intuition/classify\",\n",
    "                       json = data,\n",
    "                       headers = header)\n",
    "    json_result = result.json()\n",
    "    \n",
    "    res_dict = {\"s\":0, \"n\":0}\n",
    "    \n",
    "    for classItem in json_result[0][\"classification\"]:\n",
    "        res_dict[classItem[\"className\"]] = classItem[\"p\"]\n",
    "    \n",
    "    sorted_dict = sorted(res_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 1800 of 1800\r"
     ]
    }
   ],
   "source": [
    "zeros = np.zeros(len(perc_eval_set))\n",
    "sn_results = []\n",
    "row_cnt = 1\n",
    "for ix, row in perc_eval_set.iterrows():\n",
    "    print(\"row: {} of {}\".format(row_cnt, len(perc_eval_set)),end=\"\\r\")\n",
    "    res = classify_jung_percieving_function_of_text(row[\"text\"])\n",
    "    sn_results.append(res[0][0])\n",
    "    row_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the percieving classification results to the evaulation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  tokens perc_func  \\\n",
      "8623   Sonny Jooooooooon INDEX ASK PAST THEME Sonny J...     386         s   \n",
      "20508  void of lights void of lights Search Ask me an...    1922         s   \n",
      "4604   *tamp tamp* *tamp tamp* Index : Ask : submit :...     543         s   \n",
      "\n",
      "      judg_func actual_temp  perc_training_set sn  \n",
      "8623          f          sf                  0  s  \n",
      "20508         t          st                  0  n  \n",
      "4604          t          st                  0  s  \n"
     ]
    }
   ],
   "source": [
    "perc_eval_set = pd.concat([perc_eval_set,\n",
    "                      pd.DataFrame(sn_results, index=perc_eval_set.index)\n",
    "                     ], axis=1, ignore_index=True)\n",
    "perc_eval_set.columns = [\"text\",\"tokens\",\"perc_func\",\"judg_func\",\"actual_temp\",\"perc_training_set\",\"sn\"]\n",
    "perc_eval_set.to_pickle(\"classification_results_percieving_function_blogs_n5000_dataframe.pickle\")\n",
    "print(perc_eval_set.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_jung_judging_function_of_text(text):\n",
    "    \"\"\"Does what it says, pretty much.\"\"\"\n",
    "    header = {\"Content-Type\": \"application/json\",\n",
    "             \"Authorization\": \"Token \" + os.environ[\"UCLASSIFY_READ\"]}\n",
    "    data = {\"texts\":[text]} # send a one-item list for now, since we don't have a feel for sizes\n",
    "    result = requests.post(\"https://api.uclassify.com/v1/prfekt/jungian-cognitive-function-thinking-feeling/classify\",\n",
    "                       json = data,\n",
    "                       headers = header)\n",
    "    json_result = result.json()\n",
    "    \n",
    "    res_dict = {\"t\":0, \"f\":0}\n",
    "    \n",
    "    for classItem in json_result[0][\"classification\"]:\n",
    "        res_dict[classItem[\"className\"]] = classItem[\"p\"]\n",
    "    \n",
    "    sorted_dict = sorted(res_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 2358 of 6000\r"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.uclassify.com', port=443): Max retries exceeded with url: /v1/prfekt/jungian-cognitive-function-thinking-feeling/classify (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x1207f5438>: Failed to establish a new connection: [Errno 60] Operation timed out',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x1207f5438>: Failed to establish a new connection: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.uclassify.com', port=443): Max retries exceeded with url: /v1/prfekt/jungian-cognitive-function-thinking-feeling/classify (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x1207f5438>: Failed to establish a new connection: [Errno 60] Operation timed out',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-d6a2ce0cc57c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjudg_eval_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"row: {} of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudg_eval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_jung_judging_function_of_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrow_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-b262adb06c00>\u001b[0m in \u001b[0;36mclassify_jung_judging_function_of_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     result = requests.post(\"https://api.uclassify.com/v1/prfekt/jungian-cognitive-function-thinking-feeling/classify\",\n\u001b[1;32m      7\u001b[0m                        \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                        headers = header)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mjson_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memeticscience/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.uclassify.com', port=443): Max retries exceeded with url: /v1/prfekt/jungian-cognitive-function-thinking-feeling/classify (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x1207f5438>: Failed to establish a new connection: [Errno 60] Operation timed out',))"
     ]
    }
   ],
   "source": [
    "zeros = np.zeros(len(judg_eval_set))\n",
    "tf_results = []\n",
    "row_cnt = 1\n",
    "for ix, row in judg_eval_set.iterrows():\n",
    "    print(\"row: {} of {}\".format(row_cnt, len(judg_eval_set)),end=\"\\r\")\n",
    "    res = classify_jung_judging_function_of_text(row[\"text\"])\n",
    "    tf_results.append(res[0][0])\n",
    "    row_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add judging classification results to evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judg_eval_set = pd.concat([judg_eval_set,\n",
    "                      pd.DataFrame(tf_results, index=judg_eval_set.index)\n",
    "                     ], axis=1, ignore_index=True)\n",
    "judg_eval_set.columns = [\"text\",\"tokens\",\"perc_func\",\"judg_func\",\"actual_temp\",\"judg_training_set\",\"tf\"]\n",
    "judg_eval_set.to_pickle(\"classification_results_judging_function_blogs_n10000_dataframe.pickle\")\n",
    "print(judg_eval_set.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of percieving classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report percieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_cr = classification_report(perc_eval_set['perc_func'], perc_eval_set['sn'])\n",
    "print(sn_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percieving accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_accuracy = sum(perc_eval_set['perc_func']==perc_eval_set['sn'])/len(perc_eval_set)\n",
    "print(sn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percieving Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_kappa = (sn_accuracy - 0.5)/0.5\n",
    "print(sn_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of judging classificiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report judging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cr = classification_report(judg_eval_set['judg_func'], judg_eval_set['tf'])\n",
    "print(tf_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_accuracy = sum(judg_eval_set['judg_func']==judg_eval_set['tf'])/len(judg_eval_set)\n",
    "print(tf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judging Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kappa = (tf_accuracy - 0.5)/0.5\n",
    "print(tf_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kappa = (tf_accuracy - 0.5)/0.5\n",
    "print(tf_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and further research\n",
    "\n",
    "* Two dichotomic classifiers seems to improve the results tremendously. \n",
    "\n",
    "* Is the experiment done correctly? Peer-review the code.\n",
    "\n",
    "* Check what words, and later, phrases are the most influential for each class. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:memeticscience]",
   "language": "python",
   "name": "conda-env-memeticscience-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
