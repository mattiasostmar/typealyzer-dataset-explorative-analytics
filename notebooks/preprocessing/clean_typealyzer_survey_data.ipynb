{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related to [T63](https://mattiasostmar.phacility.com/T63) in Phabricator \n",
    "\n",
    "The raw survey-file is first copied to data/interim/<name>_cleaned.txt.\n",
    "\n",
    "That file is thereafter manually altered:\n",
    "\n",
    "- Manually removed first 123 lines, where text was still not stored by script\n",
    "- Manually removed 69 occurances of empty lines\n",
    "\n",
    "This leaves 28 311 lines in survey_2018-01-23_cleaned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unwanted semicolons\n",
    "def replace_superflous_semicolons(line, line_no):\n",
    "    \n",
    "    # remove semicolons\n",
    "    semicolons = 0\n",
    "    new_line = \"\"\n",
    "    for char in line:\n",
    "        if char == \";\":\n",
    "            semicolons += 1\n",
    "            \n",
    "        if char == \";\" and semicolons > 11: # the number of expected columns\n",
    "            new_line += \"<semic>\"\n",
    "        else:\n",
    "            new_line += char\n",
    "    \n",
    "    if len(new_line.split(\";\")) < 11:\n",
    "        return new_line.replace(\";\",\"<semic>\")\n",
    "    else:\n",
    "        return new_line\n",
    "\n",
    "def is_orphan_line(line):\n",
    "    return not line.startswith(\"http\")\n",
    "\n",
    "def remove_newlines(line):\n",
    "    return re.sub(r\"[\\n\\r\\n]\",\" \",line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data): 27959\n"
     ]
    }
   ],
   "source": [
    "f_in = open(\"../../data/interim/survey_2018-01-23_to_clean.txt\")\n",
    "f_out = open(\"../../data/processed/survey_2018-01-23_cleaned.txt\",\"w\")\n",
    "line_no = 0\n",
    "\n",
    "data = {}\n",
    "\n",
    "# ['url', 'typealyzer', 'actual', 'e', 's', 't', 'sntf_s', 'sntf_n', 'sntf_t', 'sntf_f', 'date', 'text']\n",
    "cols = [col.rstrip() for col in f_in.readline().split(\";\")]\n",
    "last_good_line = 1 # Not 0, since it's the columns line\n",
    "\n",
    "for line in f_in:\n",
    "    line_no += 1\n",
    "   \n",
    "    new_line = replace_superflous_semicolons(line, line_no)\n",
    "    new_line = remove_newlines(new_line)\n",
    "    \n",
    "    if line_no > 0 and not is_orphan_line(new_line):\n",
    "        last_good_line = line_no\n",
    "        line_data = new_line.split(\";\")\n",
    "        if not len(line_data) == 12:\n",
    "            print(\"Oops, the line data has len() {}\".format(len(line_data)))\n",
    "            print(\"line_no: {}\".format(line_no))\n",
    "            print(\"new_line: {}\".format(new_line))\n",
    "            print(\"line_data: {}\".format(\"\\nline:\".join(line_data)))\n",
    "            break\n",
    "        data[line_no] = defaultdict(dict)\n",
    "        for col in cols:\n",
    "            data[line_no][col] = None\n",
    "            \n",
    "        for (col,coldata) in zip(cols, new_line.split(\";\")):\n",
    "            data[line_no][col] = coldata\n",
    "        \n",
    "    if is_orphan_line(new_line):\n",
    "        #print(\"Suspected orphan line:\\n{}\".format(new_line))\n",
    "        #print(\"Last good lines fields:\\n{}\".format(data[last_good_line]))\n",
    "        new_line = new_line.strip(\"\\n\")\n",
    "        padded_new_line = \" \" + new_line\n",
    "        data[last_good_line][\"text\"] += padded_new_line.strip(\"\\n\")\n",
    "        #print(\"added line {}'s text to line {}\".format(line_no, last_good_line))\n",
    "\n",
    "print(\"len(data): {}\".format(len(data)))\n",
    "#print(\"data[1]:\\n{}\".format(data[1]))\n",
    "for row_nr in data:\n",
    "    row_string = \"\"\n",
    "    for key in cols:\n",
    "        separated_data = data[row_nr][key] + \";\"\n",
    "        row_string += separated_data\n",
    "    row_string = row_string.strip(\";\")\n",
    "    if row_string.endswith(\"\\n\"):\n",
    "        f_out.write(row_string)\n",
    "    else:\n",
    "        f_out.write(row_string + \"\\n\")\n",
    "f_out.close()\n",
    "f_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load final cleaned survey-file to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27959"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"../../data/processed/survey_2018-01-23_cleaned.txt\")\n",
    "names = ['url', 'typealyzer', 'actual', 'e', 's', 't', 'sntf_s', 'sntf_n', 'sntf_t', 'sntf_f', 'date', 'text']\n",
    "df = pd.read_csv(f, sep=\";\", names=names)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>typealyzer</th>\n",
       "      <th>actual</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>sntf_s</th>\n",
       "      <th>sntf_n</th>\n",
       "      <th>sntf_t</th>\n",
       "      <th>sntf_f</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://jonkagstrom.com</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.420758</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.652214</td>\n",
       "      <td>0.512359</td>\n",
       "      <td>0.274234</td>\n",
       "      <td>0.134025</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>20120828 09:08:55</td>\n",
       "      <td>Jon Kågström playchilla.com uclassify.com abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://adropofcolour.tumblr.com</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.291281</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.460961</td>\n",
       "      <td>0.663515</td>\n",
       "      <td>0.178565</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>20120828 08:08:11</td>\n",
       "      <td>❀*a drop of colour*❀ 1/39 next→ home ask past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://godheadcomplex.tumblr.com</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.883579</td>\n",
       "      <td>0.951693</td>\n",
       "      <td>0.238407</td>\n",
       "      <td>0.855921</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>20120828 09:08:34</td>\n",
       "      <td>Neko cool kids can't die home family daveblog ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                url typealyzer actual         e         s  \\\n",
       "0            http://jonkagstrom.com       ISTP   INFJ  0.420758  0.651605   \n",
       "1   http://adropofcolour.tumblr.com       ISFP   INFJ  0.291281  0.787844   \n",
       "2  http://godheadcomplex.tumblr.com       ESFP   INFP  0.883579  0.951693   \n",
       "\n",
       "          t    sntf_s    sntf_n    sntf_t    sntf_f               date  \\\n",
       "0  0.652214  0.512359  0.274234  0.134025  0.079382  20120828 09:08:55   \n",
       "1  0.460961  0.663515  0.178565  0.069282  0.088638  20120828 08:08:11   \n",
       "2  0.238407  0.855921  0.046931  0.021850  0.075297  20120828 09:08:34   \n",
       "\n",
       "                                                text  \n",
       "0  Jon Kågström playchilla.com uclassify.com abou...  \n",
       "1  ❀*a drop of colour*❀ 1/39 next→ home ask past ...  \n",
       "2  Neko cool kids can't die home family daveblog ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 27959\n",
       "unique                16318\n",
       "top       20140801 07:08:35\n",
       "freq                     25\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract domains using tldextract\n",
    "See [tldextract](https://pypi.python.org/pypi/tldextract)\n",
    "\n",
    "Note:\n",
    "co.vu is a free domain name service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tumblr                              24487\n",
       "blogspot                              590\n",
       "wordpress                             545\n",
       "co                                    285\n",
       "twitter                               248\n",
       "facebook                              170\n",
       "google                                 63\n",
       "livejournal                            53\n",
       "Tumblr                                 29\n",
       "weebly                                 28\n",
       "reddit                                 27\n",
       "okcupid                                21\n",
       "TUMBLR                                 20\n",
       "fanfiction                             20\n",
       "tumbr                                  16\n",
       "intjforum                              16\n",
       "Twitter                                15\n",
       "personalitycafe                        15\n",
       "deviantart                             15\n",
       "youtube                                14\n",
       "medium                                 13\n",
       "dreamwidth                             13\n",
       "personalityjunkie                      13\n",
       "typealyzer                             13\n",
       "pinterest                              12\n",
       "instagram                              12\n",
       "pointlesssites                         12\n",
       "ovh                                    12\n",
       "fighunter                              11\n",
       "pastebin                               10\n",
       "                                    ...  \n",
       "taricorp                                1\n",
       "we                                      1\n",
       "socialscienceresearchfunding            1\n",
       "namari                                  1\n",
       "tamerietherton                          1\n",
       "actualconversationswithmyhusband        1\n",
       "singlemuslim                            1\n",
       "eeyup                                   1\n",
       "prettyfedup                             1\n",
       "uselessfacts                            1\n",
       "thelipsticklexicon                      1\n",
       "sanderkuitert                           1\n",
       "corvoattano                             1\n",
       "Craigslist                              1\n",
       "isaacwyatt                              1\n",
       "motpol                                  1\n",
       "va                                      1\n",
       "filipinaaz                              1\n",
       "vivainstitute                           1\n",
       "rickenba                                1\n",
       "kaldahlfineart                          1\n",
       "expendablefriend                        1\n",
       "happilybackward                         1\n",
       "debug                                   1\n",
       "dearmanhattan                           1\n",
       "bloggermother                           1\n",
       "jonmorgan                               1\n",
       "gardenlilie                             1\n",
       "typologycentral                         1\n",
       "Feelingintuitive                        1\n",
       "Name: domain, Length: 910, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains = []\n",
    "for index, row in df.iterrows():\n",
    "    ext = tldextract.extract(row.url)\n",
    "    domains.append(ext.domain)\n",
    "df[\"domain\"] = pd.Series(domains)\n",
    "df.domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../pickles/dataframe_survey_2018-01-23_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/processed/dataframe_survey_2018-01-23_cleaned.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
