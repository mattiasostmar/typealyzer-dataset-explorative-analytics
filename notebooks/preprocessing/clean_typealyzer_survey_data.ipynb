{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import tldextract\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0 # To ensure reproducible language detection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related to [T63](https://mattiasostmar.phacility.com/T63) in Phabricator \n",
    "\n",
    "The raw survey-file is first copied to data/interim/<name>_cleaned.txt.\n",
    "\n",
    "That file is thereafter manually altered:\n",
    "\n",
    "- Manually removed first 123 lines, where text was still not stored by script\n",
    "- Manually removed 69 occurances of empty lines\n",
    "\n",
    "This leaves 28 311 lines in survey_2018-01-23_cleaned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unwanted semicolons\n",
    "def replace_superflous_semicolons(line, line_no):\n",
    "    \n",
    "    # remove semicolons\n",
    "    semicolons = 0\n",
    "    new_line = \"\"\n",
    "    for char in line:\n",
    "        if char == \";\":\n",
    "            semicolons += 1\n",
    "            \n",
    "        if char == \";\" and semicolons > 11: # the number of expected columns\n",
    "            new_line += \"<semic>\"\n",
    "        else:\n",
    "            new_line += char\n",
    "    \n",
    "    if len(new_line.split(\";\")) < 11:\n",
    "        return new_line.replace(\";\",\"<semic>\")\n",
    "    else:\n",
    "        return new_line\n",
    "\n",
    "def is_orphan_line(line):\n",
    "    return not line.startswith(\"http\")\n",
    "\n",
    "def remove_newlines(line):\n",
    "    return re.sub(r\"[\\n\\r\\n]\",\" \",line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data): 27959\n",
      "No of lines in orginal raw data: 28310\n"
     ]
    }
   ],
   "source": [
    "f_in = open(\"../../data/interim/survey_2018-01-23_to_clean.txt\")\n",
    "f_out = open(\"../../data/interim/survey_2018-01-23_cleaned.txt\",\"w\")\n",
    "line_no = 0\n",
    "\n",
    "data = {}\n",
    "\n",
    "# ['url', 'typealyzer', 'actual', 'e', 's', 't', 'sntf_s', 'sntf_n', 'sntf_t', 'sntf_f', 'date', 'text']\n",
    "cols = [col.rstrip() for col in f_in.readline().split(\";\")]\n",
    "last_good_line = 1 # Not 0, since it's the columns line\n",
    "\n",
    "for line in f_in:\n",
    "    line_no += 1\n",
    "   \n",
    "    new_line = replace_superflous_semicolons(line, line_no)\n",
    "    new_line = remove_newlines(new_line)\n",
    "    \n",
    "    if line_no > 0 and not is_orphan_line(new_line):\n",
    "        last_good_line = line_no\n",
    "        line_data = new_line.split(\";\")\n",
    "        if not len(line_data) == 12:\n",
    "            print(\"Oops, the line data has len() {}\".format(len(line_data)))\n",
    "            print(\"line_no: {}\".format(line_no))\n",
    "            print(\"new_line: {}\".format(new_line))\n",
    "            print(\"line_data: {}\".format(\"\\nline:\".join(line_data)))\n",
    "            break\n",
    "        data[line_no] = defaultdict(dict)\n",
    "        for col in cols:\n",
    "            data[line_no][col] = None\n",
    "            \n",
    "        for (col,coldata) in zip(cols, new_line.split(\";\")):\n",
    "            data[line_no][col] = coldata\n",
    "        \n",
    "    if is_orphan_line(new_line):\n",
    "        #print(\"Suspected orphan line:\\n{}\".format(new_line))\n",
    "        #print(\"Last good lines fields:\\n{}\".format(data[last_good_line]))\n",
    "        new_line = new_line.strip(\"\\n\")\n",
    "        padded_new_line = \" \" + new_line\n",
    "        data[last_good_line][\"text\"] += padded_new_line.strip(\"\\n\")\n",
    "        #print(\"added line {}'s text to line {}\".format(line_no, last_good_line))\n",
    "\n",
    "print(\"len(data): {}\".format(len(data)))\n",
    "#print(\"data[1]:\\n{}\".format(data[1]))\n",
    "for row_nr in data:\n",
    "    row_string = \"\"\n",
    "    for key in cols:\n",
    "        separated_data = data[row_nr][key] + \";\"\n",
    "        row_string += separated_data\n",
    "    row_string = row_string.strip(\";\")\n",
    "    if row_string.endswith(\"\\n\"):\n",
    "        f_out.write(row_string)\n",
    "    else:\n",
    "        f_out.write(row_string + \"\\n\")\n",
    "print(\"No of lines in orginal raw data: {}\".format(line_no))\n",
    "f_out.close()\n",
    "f_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning rows containing semicolons etc we have 27 959 rows left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the above cleaned survey-file to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27959"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"../../data/interim/survey_2018-01-23_cleaned.txt\")\n",
    "names = ['url', 'typealyzer', 'actual', 'e', 's', 't', 'sntf_s', 'sntf_n', 'sntf_t', 'sntf_f', 'date', 'text']\n",
    "df = pd.read_csv(f, sep=\";\", names=names)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>typealyzer</th>\n",
       "      <th>actual</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>sntf_s</th>\n",
       "      <th>sntf_n</th>\n",
       "      <th>sntf_t</th>\n",
       "      <th>sntf_f</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://jonkagstrom.com</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.420758</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.652214</td>\n",
       "      <td>0.512359</td>\n",
       "      <td>0.274234</td>\n",
       "      <td>0.134025</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>20120828 09:08:55</td>\n",
       "      <td>Jon Kågström playchilla.com uclassify.com abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://adropofcolour.tumblr.com</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.291281</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.460961</td>\n",
       "      <td>0.663515</td>\n",
       "      <td>0.178565</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>20120828 08:08:11</td>\n",
       "      <td>❀*a drop of colour*❀ 1/39 next→ home ask past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://godheadcomplex.tumblr.com</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.883579</td>\n",
       "      <td>0.951693</td>\n",
       "      <td>0.238407</td>\n",
       "      <td>0.855921</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>20120828 09:08:34</td>\n",
       "      <td>Neko cool kids can't die home family daveblog ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                url typealyzer actual         e         s  \\\n",
       "0            http://jonkagstrom.com       ISTP   INFJ  0.420758  0.651605   \n",
       "1   http://adropofcolour.tumblr.com       ISFP   INFJ  0.291281  0.787844   \n",
       "2  http://godheadcomplex.tumblr.com       ESFP   INFP  0.883579  0.951693   \n",
       "\n",
       "          t    sntf_s    sntf_n    sntf_t    sntf_f               date  \\\n",
       "0  0.652214  0.512359  0.274234  0.134025  0.079382  20120828 09:08:55   \n",
       "1  0.460961  0.663515  0.178565  0.069282  0.088638  20120828 08:08:11   \n",
       "2  0.238407  0.855921  0.046931  0.021850  0.075297  20120828 09:08:34   \n",
       "\n",
       "                                                text  \n",
       "0  Jon Kågström playchilla.com uclassify.com abou...  \n",
       "1  ❀*a drop of colour*❀ 1/39 next→ home ask past ...  \n",
       "2  Neko cool kids can't die home family daveblog ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 27959\n",
       "unique                16318\n",
       "top       20140801 07:08:35\n",
       "freq                     25\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a column with crude count of tokens in the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn_s = df.text.str.split()\n",
    "\n",
    "tkn_lens = []\n",
    "for ix, l in tkn_s.iteritems():\n",
    "    tkn_lens.append(len(l))\n",
    "    \n",
    "df[\"tokens\"] = pd.Series(tkn_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>typealyzer</th>\n",
       "      <th>actual</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>sntf_s</th>\n",
       "      <th>sntf_n</th>\n",
       "      <th>sntf_t</th>\n",
       "      <th>sntf_f</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url, typealyzer, actual, e, s, t, sntf_s, sntf_n, sntf_t, sntf_f, date, text, tokens, domain]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.isnull(df[\"tokens\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract domains using tldextract\n",
    "See [tldextract](https://pypi.python.org/pypi/tldextract)\n",
    "\n",
    "Note:\n",
    "co.vu is a free domain name service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tumblr                    24487\n",
       "blogspot                    590\n",
       "wordpress                   545\n",
       "co                          285\n",
       "twitter                     248\n",
       "facebook                    170\n",
       "google                       63\n",
       "livejournal                  53\n",
       "Tumblr                       29\n",
       "weebly                       28\n",
       "reddit                       27\n",
       "okcupid                      21\n",
       "fanfiction                   20\n",
       "TUMBLR                       20\n",
       "tumbr                        16\n",
       "intjforum                    16\n",
       "Twitter                      15\n",
       "personalitycafe              15\n",
       "deviantart                   15\n",
       "youtube                      14\n",
       "personalityjunkie            13\n",
       "dreamwidth                   13\n",
       "medium                       13\n",
       "typealyzer                   13\n",
       "instagram                    12\n",
       "ovh                          12\n",
       "pointlesssites               12\n",
       "pinterest                    12\n",
       "fighunter                    11\n",
       "pastebin                     10\n",
       "                          ...  \n",
       "susiemakessupper              1\n",
       "noisehelp                     1\n",
       "diaryland                     1\n",
       "charliemcdonnell              1\n",
       "hardballtimes                 1\n",
       "Nototherwise                  1\n",
       "reenawadia                    1\n",
       "fortheloveofbrooklyn          1\n",
       "melusine21cent                1\n",
       "filipinaaz                    1\n",
       "casafaraincalzire             1\n",
       "chemistblogger                1\n",
       "marketingsociety              1\n",
       "advancedfictionwriting        1\n",
       "introvertdear                 1\n",
       "Feelingintuitive              1\n",
       "spencertweedy                 1\n",
       "20acresnosheep                1\n",
       "earlyretirementextreme        1\n",
       "inwardfacinggirl              1\n",
       "marziaslife                   1\n",
       "nalcarya                      1\n",
       "stacyapadula                  1\n",
       "popculturecrazy               1\n",
       "githubusercontent             1\n",
       "nataliesettles                1\n",
       "daibarnes                     1\n",
       "medimoon                      1\n",
       "tim-bonner                    1\n",
       "punitdubey                    1\n",
       "Name: domain, Length: 910, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains = []\n",
    "for index, row in df.iterrows():\n",
    "    ext = tldextract.extract(row.url)\n",
    "    domains.append(ext.domain)\n",
    "df[\"domain\"] = pd.Series(domains)\n",
    "df.domain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove rows with un-translateable texts\n",
    "187 rows canno't be language classified using [langdetect](https://github.com/Mimino666/langdetect), mostly due to non-existent texts. \n",
    "\n",
    "Others contains mostly symbols, e.g. \"▲▼▲▼▲▼ ▲▼▲▼▲▼\" or \"----''. _ __ / .' /\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix: 414 error: No features in text.\n",
      "text \n",
      "ix: 424 error: No features in text.\n",
      "text/ ._> | | | '_>/ ._>| . \\/ ._>| || |/ ._> | _/\\___/`___||_| \\___. |_| |_| \\___.|___/\\___.|_||_|\\___. |_| -->  \n",
      "ix: 825 error: No features in text.\n",
      "text \n",
      "ix: 844 error: No features in text.\n",
      "text \n",
      "ix: 1378 error: No features in text.\n",
      "text \n",
      "ix: 1664 error: No features in text.\n",
      "text \n",
      "ix: 2005 error: No features in text.\n",
      "text \n",
      "ix: 2110 error: No features in text.\n",
      "text \n",
      "ix: 2272 error: No features in text.\n",
      "text \n",
      "ix: 2284 error: No features in text.\n",
      "text \n",
      "ix: 2805 error: No features in text.\n",
      "text \n",
      "ix: 2850 error: No features in text.\n",
      "text \n",
      "ix: 2851 error: No features in text.\n",
      "text \n",
      "ix: 2970 error: No features in text.\n",
      "text \n",
      "ix: 2990 error: No features in text.\n",
      "text \n",
      "ix: 3211 error: No features in text.\n",
      "text= \n",
      "ix: 3309 error: No features in text.\n",
      "text \n",
      "ix: 3743 error: No features in text.\n",
      "text \n",
      "ix: 3825 error: No features in text.\n",
      "text \n",
      "ix: 3843 error: No features in text.\n",
      "text \n",
      "ix: 3886 error: No features in text.\n",
      "text \n",
      "ix: 4010 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 4049 error: No features in text.\n",
      "text \n",
      "ix: 4079 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 4090 error: No features in text.\n",
      "text \n",
      "ix: 4164 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 4268 error: No features in text.\n",
      "text \n",
      "ix: 4321 error: No features in text.\n",
      "text \n",
      "ix: 4324 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 4626 error: No features in text.\n",
      "text \n",
      "ix: 4804 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 5041 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 5228 error: No features in text.\n",
      "text \n",
      "ix: 5468 error: No features in text.\n",
      "text \n",
      "ix: 5831 error: No features in text.\n",
      "text \n",
      "ix: 5981 error: No features in text.\n",
      "text \n",
      "ix: 6070 error: No features in text.\n",
      "text \n",
      "ix: 6089 error: No features in text.\n",
      "text \n",
      "ix: 6180 error: No features in text.\n",
      "text \n",
      "ix: 6346 error: No features in text.\n",
      "text \n",
      "ix: 6625 error: No features in text.\n",
      "text \n",
      "ix: 6661 error: No features in text.\n",
      "text \n",
      "ix: 6983 error: No features in text.\n",
      "text \n",
      "ix: 7097 error: No features in text.\n",
      "text \n",
      "ix: 7146 error: No features in text.\n",
      "text \n",
      "ix: 7207 error: No features in text.\n",
      "text \n",
      "ix: 7458 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 7480 error: No features in text.\n",
      "text \n",
      "ix: 7998 error: No features in text.\n",
      "text \n",
      "ix: 8287 error: No features in text.\n",
      "text \n",
      "ix: 8508 error: No features in text.\n",
      "text \n",
      "ix: 8614 error: No features in text.\n",
      "text \n",
      "ix: 8663 error: No features in text.\n",
      "text \n",
      "ix: 8857 error: No features in text.\n",
      "text \n",
      "ix: 8930 error: No features in text.\n",
      "text \n",
      "ix: 8931 error: No features in text.\n",
      "text \n",
      "ix: 9243 error: No features in text.\n",
      "text \n",
      "ix: 9405 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 9678 error: No features in text.\n",
      "text \n",
      "ix: 10117 error: No features in text.\n",
      "text \n",
      "ix: 10352 error: No features in text.\n",
      "text \n",
      "ix: 10362 error: No features in text.\n",
      "text \n",
      "ix: 10451 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 10455 error: No features in text.\n",
      "text \n",
      "ix: 10488 error: No features in text.\n",
      "text \n",
      "ix: 10610 error: No features in text.\n",
      "text \n",
      "ix: 10881 error: No features in text.\n",
      "text \n",
      "ix: 10971 error: No features in text.\n",
      "text \n",
      "ix: 10974 error: No features in text.\n",
      "text \n",
      "ix: 11012 error: No features in text.\n",
      "text \n",
      "ix: 11058 error: No features in text.\n",
      "text \n",
      "ix: 11142 error: No features in text.\n",
      "text \n",
      "ix: 11408 error: No features in text.\n",
      "text \n",
      "ix: 11439 error: No features in text.\n",
      "text \n",
      "ix: 11503 error: No features in text.\n",
      "text \n",
      "ix: 11520 error: No features in text.\n",
      "text \n",
      "ix: 11622 error: No features in text.\n",
      "text \n",
      "ix: 11930 error: No features in text.\n",
      "text \n",
      "ix: 12234 error: No features in text.\n",
      "textᴘʟᴇᴀsᴇ ᴅᴏ ɴᴏᴛ ʀᴇᴍᴏᴠᴇ ᴄʀᴇᴅɪᴛ. ғᴇᴇʟ ғʀᴇᴇ ᴛᴏ ᴀsᴋ ɪғ ʏᴏᴜ ʜᴀᴠᴇ ᴀɴʏ ǫᴜᴇsᴛɪᴏɴs! ---------------------------------------------------------------------->  \n",
      "ix: 12477 error: No features in text.\n",
      "text \n",
      "ix: 12582 error: No features in text.\n",
      "text \n",
      "ix: 12610 error: No features in text.\n",
      "text \n",
      "ix: 12633 error: No features in text.\n",
      "text \n",
      "ix: 13169 error: No features in text.\n",
      "text \n",
      "ix: 13170 error: No features in text.\n",
      "text \n",
      "ix: 13176 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 13347 error: No features in text.\n",
      "text \n",
      "ix: 13399 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 13471 error: No features in text.\n",
      "text \n",
      "ix: 13481 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 13618 error: No features in text.\n",
      "text \n",
      "ix: 13622 error: No features in text.\n",
      "text \n",
      "ix: 13625 error: No features in text.\n",
      "text \n",
      "ix: 13780 error: No features in text.\n",
      "text \n",
      "ix: 13982 error: No features in text.\n",
      "text \n",
      "ix: 14101 error: No features in text.\n",
      "text \n",
      "ix: 14183 error: No features in text.\n",
      "text \n",
      "ix: 14251 error: No features in text.\n",
      "text \n",
      "ix: 14370 error: No features in text.\n",
      "text \n",
      "ix: 14563 error: No features in text.\n",
      "text \n",
      "ix: 14618 error: No features in text.\n",
      "text \n",
      "ix: 14707 error: No features in text.\n",
      "text \n",
      "ix: 15399 error: No features in text.\n",
      "text \n",
      "ix: 15430 error: No features in text.\n",
      "text \n",
      "ix: 15497 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 15845 error: No features in text.\n",
      "text \n",
      "ix: 16030 error: No features in text.\n",
      "text \n",
      "ix: 16273 error: No features in text.\n",
      "text \n",
      "ix: 16405 error: No features in text.\n",
      "text \n",
      "ix: 16476 error: No features in text.\n",
      "text \n",
      "ix: 16493 error: No features in text.\n",
      "text \n",
      "ix: 16497 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 16498 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 16586 error: No features in text.\n",
      "text \n",
      "ix: 16982 error: No features in text.\n",
      "text \n",
      "ix: 17009 error: No features in text.\n",
      "text \n",
      "ix: 17057 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 17058 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 17392 error: No features in text.\n",
      "text \n",
      "ix: 17423 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 17439 error: No features in text.\n",
      "text \n",
      "ix: 17453 error: No features in text.\n",
      "text \n",
      "ix: 17650 error: No features in text.\n",
      "text \n",
      "ix: 17697 error: No features in text.\n",
      "text \n",
      "ix: 17699 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 18345 error: No features in text.\n",
      "text \n",
      "ix: 18536 error: No features in text.\n",
      "text \n",
      "ix: 18603 error: No features in text.\n",
      "text \n",
      "ix: 18743 error: No features in text.\n",
      "text \n",
      "ix: 18905 error: No features in text.\n",
      "text \n",
      "ix: 19059 error: No features in text.\n",
      "text \n",
      "ix: 19062 error: No features in text.\n",
      "text \n",
      "ix: 19175 error: No features in text.\n",
      "text \n",
      "ix: 19209 error: No features in text.\n",
      "text \n",
      "ix: 19425 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 19591 error: No features in text.\n",
      "text'.'<) ( \n",
      "ix: 19707 error: No features in text.\n",
      "text \n",
      "ix: 19936 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 20031 error: No features in text.\n",
      "text \n",
      "ix: 20451 error: No features in text.\n",
      "text \n",
      "ix: 20578 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 20614 error: No features in text.\n",
      "text \n",
      "ix: 20756 error: No features in text.\n",
      "text \n",
      "ix: 20807 error: No features in text.\n",
      "text \n",
      "ix: 20882 error: No features in text.\n",
      "text \n",
      "ix: 20883 error: No features in text.\n",
      "text \n",
      "ix: 20884 error: No features in text.\n",
      "text \n",
      "ix: 20951 error: No features in text.\n",
      "text \n",
      "ix: 21100 error: No features in text.\n",
      "text \n",
      "ix: 21180 error: No features in text.\n",
      "text \n",
      "ix: 21276 error: No features in text.\n",
      "text \n",
      "ix: 21628 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 21767 error: No features in text.\n",
      "text \n",
      "ix: 21997 error: No features in text.\n",
      "text \n",
      "ix: 22006 error: No features in text.\n",
      "text \n",
      "ix: 22247 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 22478 error: No features in text.\n",
      "text \n",
      "ix: 22506 error: No features in text.\n",
      "text \n",
      "ix: 22617 error: No features in text.\n",
      "text \n",
      "ix: 22693 error: No features in text.\n",
      "text \n",
      "ix: 22969 error: No features in text.\n",
      "text \n",
      "ix: 23326 error: No features in text.\n",
      "text \n",
      "ix: 23327 error: No features in text.\n",
      "text \n",
      "ix: 23452 error: No features in text.\n",
      "text▲▼▲▼▲▼ ▲▼▲▼▲▼  \n",
      "ix: 23637 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 23638 error: No features in text.\n",
      "text \n",
      "ix: 23755 error: No features in text.\n",
      "text \n",
      "ix: 23801 error: No features in text.\n",
      "text \n",
      "ix: 23854 error: No features in text.\n",
      "text----''. _ __ / .' / \n",
      "ix: 24292 error: No features in text.\n",
      "text \n",
      "ix: 24333 error: No features in text.\n",
      "text \n",
      "ix: 24480 error: No features in text.\n",
      "text \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix: 24813 error: No features in text.\n",
      "text \n",
      "ix: 24843 error: No features in text.\n",
      "text \n",
      "ix: 24861 error: No features in text.\n",
      "text \n",
      "ix: 25524 error: No features in text.\n",
      "text \n",
      "ix: 25535 error: No features in text.\n",
      "text \n",
      "ix: 26024 error: No features in text.\n",
      "text \n",
      "ix: 26052 error: No features in text.\n",
      "text \n",
      "ix: 26072 error: No features in text.\n",
      "text \n",
      "ix: 26154 error: No features in text.\n",
      "text \n",
      "ix: 26155 error: No features in text.\n",
      "text \n",
      "ix: 26194 error: No features in text.\n",
      "text \n",
      "ix: 26398 error: No features in text.\n",
      "text \n",
      "ix: 26754 error: No features in text.\n",
      "text \n",
      "ix: 27647 error: No features in text.\n",
      "text \n",
      "ix: 27908 error: No features in text.\n",
      "text \n",
      "No of un-transtanslateable rows: 187\n"
     ]
    }
   ],
   "source": [
    "error_ix = []\n",
    "langs = []\n",
    "for ix, row in df.iterrows():\n",
    "    try:\n",
    "        langs.append(detect(row[\"text\"]))\n",
    "    except Exception as e:\n",
    "        print(\"ix: {} error: {}\\ntext{}\".format(ix, e, row[\"text\"]))\n",
    "        error_ix.append(ix)\n",
    "print(\"No of un-transtanslateable rows: {}\".format(len(error_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(error_ix)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 27 772 rows left from the original raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../pickles/dataframe_survey_2018-01-23_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/interim/dataframe_survey_2018-01-23_cleaned.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:memeticscience]",
   "language": "python",
   "name": "conda-env-memeticscience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
