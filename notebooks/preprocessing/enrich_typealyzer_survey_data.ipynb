{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../pickles/dataframe_survey_2018-01-23_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carl Jungs functions and attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"t\":[\"ESTJ\",\"ENTJ\",\"ISTP\",\"INTP\"],\n",
    "    \"f\":[\"ESFJ\",\"ENFJ\",\"ISFP\",\"INFP\"],\n",
    "    \"n\":[\"ENTP\",\"ENFP\",\"INTJ\",\"INFJ\"],\n",
    "    \"s\":[\"ESTP\",\"ESFP\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "atts = {\n",
    "    \"e\":[\"ESTJ\",\"ENTJ\",\"ESFJ\",\"ENFJ\",\"ENTP\",\"ENFP\",\"ESTP\",\"ESFP\"],\n",
    "    \"i\":[\"ISTP\",\"INTP\",\"ISFP\",\"INFP\",\"INTJ\",\"INFJ\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "funcatts = {\n",
    "    \"te\":[\"ESTJ\",\"ENTJ\"],\n",
    "    \"ti\":[\"ISTP\",\"INTP\"],\n",
    "    \"fe\":[\"ESFJ\",\"ENFJ\"],\n",
    "    \"fi\":[\"ISFP\",\"INFP\"],\n",
    "    \"ne\":[\"ENTP\",\"ENFP\"],\n",
    "    \"ni\":[\"INTJ\",\"INFJ\"],\n",
    "    \"se\":[\"ESTP\",\"ESFP\"],\n",
    "    \"si\":[\"ISTJ\",\"ISFJ\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funclist = []\n",
    "attlist = []\n",
    "funcattlist = []\n",
    "\n",
    "for ix, row in df.iterrows():\n",
    "    # functions\n",
    "    for key in funcs:\n",
    "        if row[\"actual\"] in funcs[key]:\n",
    "            funclist.append(key)\n",
    "    \n",
    "    # attitudes\n",
    "    for key in atts:\n",
    "        if row[\"actual\"] in atts[key]:\n",
    "            attlist.append(key) \n",
    "            \n",
    "    # functions with attitudes\n",
    "    for key in funcatts:\n",
    "        if row[\"actual\"] in funcatts[key]:\n",
    "            funcattlist.append(key) \n",
    "\n",
    "fs = pd.Series(funclist)\n",
    "df[\"func\"] = fs\n",
    "ats = pd.Series(attlist)\n",
    "df[\"att\"] = ats\n",
    "fas = pd.Series(funcattlist)\n",
    "df[\"funcatt\"] = fas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# James Pennebakers LIWC 2007\n",
    "\n",
    "[The Development of LIWC 2007](http://www.liwc.net/LIWC2007LanguageManual.pdf)\n",
    "\n",
    "[Personality Detection by Analysis of Twitter Profiles, Mehul Smriti Raje, Aakarsh Singh](https://books.google.se/books?id=s9IxDwAAQBAJ&lpg=PA675&ots=KVsRfV0yw4&dq=liwc%20jung&pg=PA670#v=onepage&q=liwc%20jung&f=false)\n",
    "\n",
    "[The Development of LIWC 2015](https://repositories.lib.utexas.edu/bitstream/handle/2152/31333/LIWC2015_LanguageManual.pdf)\n",
    "\n",
    "[Such Stuff as Dreams Are Made On; Dream Language, LIWC Norms and Personality Correlates](https://www.researchgate.net/publication/316109197_Such_Stuff_as_Dreams_Are_Made_On_Dream_Language_LIWC_Norms_Personality_Correlates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = pickle.load(open(\"../pickles/liwc_2007_cats_dict.pickle\",\"rb\"))\n",
    "words = pickle.load(open(\"../pickles/liwc_2007_words_dict.pickle\",\"rb\"))\n",
    "    \n",
    "cats_names = []\n",
    "for key in cats.keys():\n",
    "    cats_names.append(cats[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_punctuation_with_whitespace(original_string):\n",
    "   return re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", original_string) # todo: not perfect - leaves \"),\"\n",
    "\n",
    "\n",
    "def liwc_analysis_on_english_string(original_string, words):\n",
    "    \"\"\"\n",
    "    Takes a string and returns word frequencies according to (most of) LIWC 2007.\n",
    "    \n",
    "    :param original_string: string representing the input text with no transformations.\n",
    "    :param words: dictionary containing categories as keys with 0.0 as values plus \"WC\" = word count.\n",
    "    :return: dictionary containg LIWC 2007 categories minus the psychological summary variables. \n",
    "    \"\"\" \n",
    "    liwc = dict.fromkeys(cats_names, 0.0)\n",
    "    punct_token_text = separate_punctuation_with_whitespace(original_string)\n",
    "    liwc[\"WC\"] = len(punct_token_text.split()) # TODO: implement proper tokenization before word count\n",
    "\n",
    "    for word in words:\n",
    "        regex_word = re.sub(r\"\\*\",r\"\\w+\",word) # e.g. 'cousin*' in .dic file transformed into 'cousin\\w+'\n",
    "        word_patt = re.compile(regex_word)\n",
    "        \n",
    "        if word_patt.search(original_string):\n",
    "            matches = word_patt.findall(original_string)\n",
    "            #print(\"word: {}\".format(word))\n",
    "            #print(\"cat numbers: {}\".format(words[word]))\n",
    "            try:\n",
    "                for cat_no in words[word]:\n",
    "                    if liwc.get(cats[cat_no]):\n",
    "                        liwc[cats[cat_no]] += (len(matches) / liwc[\"WC\"])   \n",
    "                    else:\n",
    "                        liwc[cats[cat_no]] = (len(matches) / liwc[\"WC\"])\n",
    "            except TypeError as e:\n",
    "                print(\"TypeError with cat_no = {}\\n{}\".format(cat_no, e))\n",
    "    \n",
    "    return liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare storage for LIWC-results per row\n",
    "liwcresults = defaultdict(list)\n",
    "liwcresults[\"WC\"] = [] # Remeber to store the word count separately, since it's not in LIWC categories\n",
    "for cat in cats_names:\n",
    "    liwcresults[cat] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished counting LIWC words!\n"
     ]
    }
   ],
   "source": [
    "# Warning, takes time on an 1,8 GHz Intel Core i5 with 8GB memory\n",
    "for ix, row in df.iterrows():\n",
    "    liwc = liwc_analysis_on_english_string(row[\"text\"], words)\n",
    "    for cat in cats_names:\n",
    "        liwcresults[cat].append(liwc[cat])\n",
    "    liwcresults[\"WC\"].append(liwc[\"WC\"])\n",
    "    print(\"row: {} WC: {}\".format(ix, liwc[\"WC\"]), end=\"\\r\")\n",
    "\n",
    "# Add LIWC-results from memory storage as Pandas Series objects to DataFrame\n",
    "for cat in cats_names:\n",
    "    s = pd.Series(liwcresults[cat])\n",
    "    df[cat] = s\n",
    "\n",
    "print(\"Finished counting LIWC words!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>typealyzer</th>\n",
       "      <th>actual</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>sntf_s</th>\n",
       "      <th>sntf_n</th>\n",
       "      <th>sntf_t</th>\n",
       "      <th>sntf_f</th>\n",
       "      <th>...</th>\n",
       "      <th>ppron</th>\n",
       "      <th>home</th>\n",
       "      <th>cause</th>\n",
       "      <th>assent</th>\n",
       "      <th>verb</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>death</th>\n",
       "      <th>time</th>\n",
       "      <th>discrep</th>\n",
       "      <th>health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://jonkagstrom.com</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.420758</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.652214</td>\n",
       "      <td>0.512359</td>\n",
       "      <td>0.274234</td>\n",
       "      <td>0.134025</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449263</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.017518</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.190558</td>\n",
       "      <td>0.125614</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.065157</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.024140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://adropofcolour.tumblr.com</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.291281</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.460961</td>\n",
       "      <td>0.663515</td>\n",
       "      <td>0.178565</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369196</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.023783</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.180068</td>\n",
       "      <td>0.108720</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.069083</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.011325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://godheadcomplex.tumblr.com</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.883579</td>\n",
       "      <td>0.951693</td>\n",
       "      <td>0.238407</td>\n",
       "      <td>0.855921</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.019704</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.039409</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.147783</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.014778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                url typealyzer actual         e         s  \\\n",
       "0            http://jonkagstrom.com       ISTP   INFJ  0.420758  0.651605   \n",
       "1   http://adropofcolour.tumblr.com       ISFP   INFJ  0.291281  0.787844   \n",
       "2  http://godheadcomplex.tumblr.com       ESFP   INFP  0.883579  0.951693   \n",
       "\n",
       "          t    sntf_s    sntf_n    sntf_t    sntf_f    ...        ppron  \\\n",
       "0  0.652214  0.512359  0.274234  0.134025  0.079382    ...     0.449263   \n",
       "1  0.460961  0.663515  0.178565  0.069282  0.088638    ...     0.369196   \n",
       "2  0.238407  0.855921  0.046931  0.021850  0.075297    ...     0.428571   \n",
       "\n",
       "       home     cause    assent      verb   auxverb     death      time  \\\n",
       "0  0.004700  0.017518  0.043580  0.190558  0.125614  0.005982  0.065157   \n",
       "1  0.005663  0.023783  0.031710  0.180068  0.108720  0.004530  0.069083   \n",
       "2  0.019704  0.004926  0.039409  0.206897  0.147783  0.014778  0.024631   \n",
       "\n",
       "    discrep    health  \n",
       "0  0.012177  0.024140  \n",
       "1  0.016988  0.011325  \n",
       "2  0.014778  0.014778  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'typealyzer', 'actual', 'e', 's', 't', 'sntf_s', 'sntf_n',\n",
       "       'sntf_t', 'sntf_f', 'date', 'text', 'domains', 'domain', 'func', 'att',\n",
       "       'funcatt', 'sexual', 'i', 'filler', 'you', 'preps', 'friend', 'affect',\n",
       "       'conj', 'see', 'adverb', 'humans', 'relig', 'ingest', 'percept', 'incl',\n",
       "       'body', 'they', 'excl', 'bio', 'work', 'leisure', 'number', 'ipron',\n",
       "       'shehe', 'we', 'inhib', 'certain', 'money', 'pronoun', 'present',\n",
       "       'social', 'family', 'swear', 'cogmech', 'nonfl', 'posemo', 'future',\n",
       "       'hear', 'achieve', 'space', 'anx', 'sad', 'article', 'past', 'negemo',\n",
       "       'tentat', 'quant', 'motion', 'insight', 'relativ', 'funct', 'feel',\n",
       "       'anger', 'negate', 'ppron', 'home', 'cause', 'assent', 'verb',\n",
       "       'auxverb', 'death', 'time', 'discrep', 'health'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20120828 09:08:55\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['datetime'] =  pd.to_datetime(df['date'], format='%Y%m%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 1-hot categorical dummies for Jungian categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attitudes (E, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_e</th>\n",
       "      <th>is_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_e  is_i\n",
       "0     0     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_cat = df.att.astype(\"category\")\n",
    "att_dummies = pd.get_dummies(att_cat)\n",
    "att_dummies = att_dummies.rename({\"e\":\"is_e\", \"i\":\"is_i\"}, axis=\"columns\")\n",
    "df = pd.concat([df,att_dummies], axis=1)\n",
    "att_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions (S, N, T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_f</th>\n",
       "      <th>is_n</th>\n",
       "      <th>is_s</th>\n",
       "      <th>is_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_f  is_n  is_s  is_t\n",
       "0     0     1     0     0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_cat = df.func.astype(\"category\")\n",
    "func_dummies = pd.get_dummies(func_cat)\n",
    "func_dummies = func_dummies.rename({\"f\":\"is_f\", \n",
    "                                    \"n\":\"is_n\", \n",
    "                                    \"s\":\"is_s\", \n",
    "                                    \"t\":\"is_t\"}, axis=\"columns\")\n",
    "df = pd.concat([df,func_dummies], axis=1)\n",
    "func_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions with attitudes (Si, Se, Ni, Ne, Ti, Te, Fi, Fe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fe</th>\n",
       "      <th>is_fi</th>\n",
       "      <th>is_ne</th>\n",
       "      <th>is_ni</th>\n",
       "      <th>is_se</th>\n",
       "      <th>is_si</th>\n",
       "      <th>is_te</th>\n",
       "      <th>is_ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fe  is_fi  is_ne  is_ni  is_se  is_si  is_te  is_ti\n",
       "0      0      0      0      1      0      0      0      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcatt_cat = df.funcatt.astype(\"category\")\n",
    "funcatt_dummies = pd.get_dummies(funcatt_cat)\n",
    "funcatt_dummies = funcatt_dummies.rename({\"fe\":\"is_fe\", \n",
    "                                          \"fi\":\"is_fi\",\n",
    "                                          \"ne\":\"is_ne\",\n",
    "                                          \"ni\":\"is_ni\",\n",
    "                                          \"se\":\"is_se\",\n",
    "                                          \"si\":\"is_si\",\n",
    "                                          \"te\":\"is_te\",\n",
    "                                          \"ti\":\"is_ti\"\n",
    "                                            }, axis=\"columns\")\n",
    "df = pd.concat([df,funcatt_dummies], axis=1)\n",
    "funcatt_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jung-Meyers types (ENTJ, ISFP etc.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array(['INFJ', 'INFP', 'INTP', \"I don't know\", 'ENFJ', 'ENFP', 'INTJ',\n",
    "       'ENTP', 'ISTJ', 'ISFJ', 'ESFP', 'ISFP', 'ISTP', 'ENTJ', 'ESFJ',\n",
    "       'ESTJ', 'ESTP'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_enfj</th>\n",
       "      <th>is_enfp</th>\n",
       "      <th>is_entj</th>\n",
       "      <th>is_entp</th>\n",
       "      <th>is_esfj</th>\n",
       "      <th>is_esfp</th>\n",
       "      <th>is_estj</th>\n",
       "      <th>is_estp</th>\n",
       "      <th>is_unknown</th>\n",
       "      <th>is_infj</th>\n",
       "      <th>is_infp</th>\n",
       "      <th>is_intj</th>\n",
       "      <th>is_intp</th>\n",
       "      <th>is_isfj</th>\n",
       "      <th>is_isfp</th>\n",
       "      <th>is_istj</th>\n",
       "      <th>is_istp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_enfj  is_enfp  is_entj  is_entp  is_esfj  is_esfp  is_estj  is_estp  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   is_unknown  is_infj  is_infp  is_intj  is_intp  is_isfj  is_isfp  is_istj  \\\n",
       "0           0        1        0        0        0        0        0        0   \n",
       "\n",
       "   is_istp  \n",
       "0        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_cat = df.actual.astype(\"category\")\n",
    "type_dummies = pd.get_dummies(type_cat)\n",
    "type_dummies = type_dummies.rename({\"INFJ\":\"is_infj\", \n",
    "                                    \"INFP\":\"is_infp\",\n",
    "                                    \"INTP\":\"is_intp\",\n",
    "                                    \"ENFJ\":\"is_enfj\",\n",
    "                                    \"ENFP\":\"is_enfp\",\n",
    "                                    \"INTJ\":\"is_intj\",\n",
    "                                    \"ENTP\":\"is_entp\",\n",
    "                                    \"ISTJ\":\"is_istj\",\n",
    "                                    \"ISFJ\":\"is_isfj\",\n",
    "                                    \"ESFP\":\"is_esfp\",\n",
    "                                    \"ISFP\":\"is_isfp\",\n",
    "                                    \"ISTP\":\"is_istp\",\n",
    "                                    \"ENTJ\":\"is_entj\",\n",
    "                                    \"ESFJ\":\"is_esfj\",\n",
    "                                    \"ESTJ\":\"is_estj\",\n",
    "                                    \"ESTP\":\"is_estp\",\n",
    "                                    \"I don't know\":\"is_unknown\"\n",
    "                                    }, axis=\"columns\")\n",
    "df = pd.concat([df,type_dummies], axis=1)\n",
    "type_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple tokenization and word count for each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens = []\n",
    "for index, text in df.text.iteritems():\n",
    "    lens.append(len(text.split()))\n",
    "df[\"tokens\"] = pd.Series(lens)\n",
    "\n",
    "quants = pd.qcut(df.tokens, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 118.0]     5596\n",
       "(118.0, 282.0]      5614\n",
       "(282.0, 445.0]      5588\n",
       "(445.0, 740.0]      5571\n",
       "(740.0, 32016.0]    5590\n",
       "Name: tokens, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quants.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store enriched DataFrame to pickle and semicolon-separated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"../pickles/dataframe_survey_2018-01-23_jung-liwc-dt-jung_onehot_tokens-enriched.pickle\")\n",
    "df.to_csv(\"../data/processed/dataframe_survey_2018-01-23_jung-liwc-dt-jung_onehot_tokens-enriched.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Find a reasonable threshold for number of tokens for training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mt100_df = df[df[\"tokens\"] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ni    7250\n",
       "fi    5196\n",
       "ti    4114\n",
       "ne    2093\n",
       "si    1928\n",
       "fe     743\n",
       "se     573\n",
       "te     502\n",
       "Name: funcatt, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt100_df.funcatt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
