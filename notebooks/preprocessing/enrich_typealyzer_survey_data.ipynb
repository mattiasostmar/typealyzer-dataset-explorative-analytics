{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27772 entries, 0 to 27958\n",
      "Columns: 114 entries, url to number\n",
      "dtypes: datetime64[ns](1), float64(71), int64(1), object(10), uint8(31)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# If re-run\n",
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual    I don't know\n",
       "func               NaN\n",
       "Name: 27930, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[27930]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0 # To ensure reproducible language detection results\n",
    "import string\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27772 entries, 0 to 27771\n",
      "Data columns (total 14 columns):\n",
      "url           27772 non-null object\n",
      "typealyzer    27772 non-null object\n",
      "actual        27772 non-null object\n",
      "e             27772 non-null float64\n",
      "s             27772 non-null float64\n",
      "t             27772 non-null float64\n",
      "sntf_s        27772 non-null float64\n",
      "sntf_n        27772 non-null float64\n",
      "sntf_t        27772 non-null float64\n",
      "sntf_f        27772 non-null float64\n",
      "date          27772 non-null object\n",
      "text          27772 non-null object\n",
      "tokens        27772 non-null int64\n",
      "domain        27772 non-null object\n",
      "dtypes: float64(7), int64(1), object(6)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_cleaned.pickle\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add language classification result to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current ix: 27771\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "en    27359\n",
       "fr       54\n",
       "da       40\n",
       "no       28\n",
       "de       28\n",
       "sv       27\n",
       "tl       16\n",
       "ca       16\n",
       "ja       15\n",
       "es       15\n",
       "nl       15\n",
       "it       14\n",
       "af       14\n",
       "et       13\n",
       "ro       13\n",
       "so       12\n",
       "cy       11\n",
       "id       10\n",
       "pt        9\n",
       "ko        9\n",
       "fi        7\n",
       "el        5\n",
       "sl        5\n",
       "pl        5\n",
       "lv        4\n",
       "bn        4\n",
       "lt        3\n",
       "sk        2\n",
       "cs        2\n",
       "sq        2\n",
       "sw        2\n",
       "vi        2\n",
       "uk        2\n",
       "ar        2\n",
       "tr        2\n",
       "hi        1\n",
       "ru        1\n",
       "hr        1\n",
       "ta        1\n",
       "mk        1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = []\n",
    "for ix, row in df.iterrows():\n",
    "    print(\"current ix: {}\".format(ix), end=\"\\r\")\n",
    "    try:\n",
    "        langs.append(detect(row[\"text\"]))\n",
    "    except:\n",
    "        print(\"ix: {} tokens: {}\\ntext{}\".format(ix, row[\"tokens\"], row[\"text\"]))\n",
    "df[\"lang\"] = pd.Series(langs)\n",
    "df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max datetime: 2018-01-22 05:01:47, Min datetime: 2012-08-28 08:08:11\n"
     ]
    }
   ],
   "source": [
    "df['datetime'] =  pd.to_datetime(df['date'], format='%Y%m%d %H:%M:%S')\n",
    "print(\"Max datetime: {}, Min datetime: {}\".format(df.datetime.max(), df.datetime.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carl Jungs functions and attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27114"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"t\":[\"ESTJ\",\"ENTJ\",\"ISTP\",\"INTP\"],\n",
    "    \"f\":[\"ESFJ\",\"ENFJ\",\"ISFP\",\"INFP\"],\n",
    "    \"n\":[\"ENTP\",\"ENFP\",\"INTJ\",\"INFJ\"],\n",
    "    \"s\":[\"ESTP\",\"ESFP\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "atts = {\n",
    "    \"e\":[\"ESTJ\",\"ENTJ\",\"ESFJ\",\"ENFJ\",\"ENTP\",\"ENFP\",\"ESTP\",\"ESFP\"],\n",
    "    \"i\":[\"ISTP\",\"INTP\",\"ISFP\",\"INFP\",\"INTJ\",\"INFJ\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "funcatts = {\n",
    "    \"te\":[\"ESTJ\",\"ENTJ\"],\n",
    "    \"ti\":[\"ISTP\",\"INTP\"],\n",
    "    \"fe\":[\"ESFJ\",\"ENFJ\"],\n",
    "    \"fi\":[\"ISFP\",\"INFP\"],\n",
    "    \"ne\":[\"ENTP\",\"ENFP\"],\n",
    "    \"ni\":[\"INTJ\",\"INFJ\"],\n",
    "    \"se\":[\"ESTP\",\"ESFP\"],\n",
    "    \"si\":[\"ISTJ\",\"ISFJ\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df): 27114\n",
      "len(fs): 27114\n",
      "len(ats): 27114\n",
      "len(fas): 27114\n"
     ]
    }
   ],
   "source": [
    "funclist = []\n",
    "attlist = []\n",
    "funcattlist = []\n",
    "\n",
    "for ix, row in df.iterrows():\n",
    "    #print(ix, end=\"\\r\")\n",
    "    # functions\n",
    "    key_found = None\n",
    "    for key_no, key in enumerate(funcs):\n",
    "        if row[\"actual\"] in funcs[key]:\n",
    "            funclist.append(key)\n",
    "            key_found = 1\n",
    "        elif key_no == 3 and not key_found:\n",
    "            funclist.append(np.nan)\n",
    "        current_key += 1\n",
    "    \n",
    "    # attitudes\n",
    "    key_found = None\n",
    "    for key_no, key in enumerate(atts):\n",
    "        if row[\"actual\"] in atts[key]:\n",
    "            attlist.append(key)\n",
    "            key_found = 1\n",
    "        elif key_no == 1 and not key_found:\n",
    "            attlist.append(np.nan)\n",
    "            \n",
    "    # functions with attitudes\n",
    "    key_found = None\n",
    "    for key_no, key in enumerate(funcatts):\n",
    "        if row[\"actual\"] in funcatts[key]:\n",
    "            funcattlist.append(key)\n",
    "            key_found = 1\n",
    "        elif key_no == 7 and not key_found:\n",
    "            funcattlist.append(np.nan)\n",
    "        current_key += 1\n",
    "        \n",
    "\n",
    "fs = pd.Series(funclist)\n",
    "df[\"func\"] = fs\n",
    "ats = pd.Series(attlist)\n",
    "df[\"att\"] = ats\n",
    "fas = pd.Series(funcattlist)\n",
    "df[\"funcatt\"] = fas\n",
    "print(\"len(df): {}\".format(len(df)))\n",
    "print(\"len(fs): {}\".format(len(fs)))\n",
    "print(\"len(ats): {}\".format(len(ats)))\n",
    "print(\"len(fas): {}\".format(len(fas)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[[\"actual\",\"func\"]][pd.isnull(df.func)]) # how many \"I don't know\" responses do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26469"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add derived two-letter type, \"temperament\" to samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mos/anaconda3/envs/memeticscience/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Add derived two-letter type. \"temperament\"\n",
    "all_two_letters = df.actual.str.extract(\"\\w(\\w\\w)\\w\")\n",
    "all_two_letters = all_two_letters.replace(\"no\",np.nan)\n",
    "df[\"actual_temp\"] = all_two_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 1-hot categorical dummies for Jungian categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attitudes (E, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_e</th>\n",
       "      <th>is_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_e  is_i\n",
       "0     0     1\n",
       "1     0     1\n",
       "2     0     1\n",
       "3     0     1\n",
       "5     1     0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_cat = df.att.astype(\"category\")\n",
    "att_dummies = pd.get_dummies(att_cat)\n",
    "att_dummies = att_dummies.rename({\"e\":\"is_e\", \"i\":\"is_i\"}, axis=\"columns\")\n",
    "df = pd.concat([df,att_dummies], axis=1)\n",
    "att_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions (S, N, T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_f</th>\n",
       "      <th>is_n</th>\n",
       "      <th>is_s</th>\n",
       "      <th>is_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_f  is_n  is_s  is_t\n",
       "0     0     1     0     0\n",
       "1     0     1     0     0\n",
       "2     1     0     0     0\n",
       "3     0     0     0     1\n",
       "5     1     0     0     0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_cat = df.func.astype(\"category\")\n",
    "func_dummies = pd.get_dummies(func_cat)\n",
    "func_dummies = func_dummies.rename({\"f\":\"is_f\", \n",
    "                                    \"n\":\"is_n\", \n",
    "                                    \"s\":\"is_s\", \n",
    "                                    \"t\":\"is_t\"}, axis=\"columns\")\n",
    "df = pd.concat([df,func_dummies], axis=1)\n",
    "func_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions with attitudes (Si, Se, Ni, Ne, Ti, Te, Fi, Fe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fe</th>\n",
       "      <th>is_fi</th>\n",
       "      <th>is_ne</th>\n",
       "      <th>is_ni</th>\n",
       "      <th>is_se</th>\n",
       "      <th>is_si</th>\n",
       "      <th>is_te</th>\n",
       "      <th>is_ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fe  is_fi  is_ne  is_ni  is_se  is_si  is_te  is_ti\n",
       "0      0      0      0      1      0      0      0      0\n",
       "1      0      0      0      1      0      0      0      0\n",
       "2      0      1      0      0      0      0      0      0\n",
       "3      0      0      0      0      0      0      0      1\n",
       "5      1      0      0      0      0      0      0      0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcatt_cat = df.funcatt.astype(\"category\")\n",
    "funcatt_dummies = pd.get_dummies(funcatt_cat)\n",
    "funcatt_dummies = funcatt_dummies.rename({\"fe\":\"is_fe\", \n",
    "                                          \"fi\":\"is_fi\",\n",
    "                                          \"ne\":\"is_ne\",\n",
    "                                          \"ni\":\"is_ni\",\n",
    "                                          \"se\":\"is_se\",\n",
    "                                          \"si\":\"is_si\",\n",
    "                                          \"te\":\"is_te\",\n",
    "                                          \"ti\":\"is_ti\"\n",
    "                                            }, axis=\"columns\")\n",
    "df = pd.concat([df,funcatt_dummies], axis=1)\n",
    "funcatt_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jung-Meyers types (ENTJ, ISFP etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_enfj</th>\n",
       "      <th>is_enfp</th>\n",
       "      <th>is_entj</th>\n",
       "      <th>is_entp</th>\n",
       "      <th>is_esfj</th>\n",
       "      <th>is_esfp</th>\n",
       "      <th>is_estj</th>\n",
       "      <th>is_estp</th>\n",
       "      <th>is_infj</th>\n",
       "      <th>is_infp</th>\n",
       "      <th>is_intj</th>\n",
       "      <th>is_intp</th>\n",
       "      <th>is_isfj</th>\n",
       "      <th>is_isfp</th>\n",
       "      <th>is_istj</th>\n",
       "      <th>is_istp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_enfj  is_enfp  is_entj  is_entp  is_esfj  is_esfp  is_estj  is_estp  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "5        1        0        0        0        0        0        0        0   \n",
       "\n",
       "   is_infj  is_infp  is_intj  is_intp  is_isfj  is_isfp  is_istj  is_istp  \n",
       "0        1        0        0        0        0        0        0        0  \n",
       "1        1        0        0        0        0        0        0        0  \n",
       "2        0        1        0        0        0        0        0        0  \n",
       "3        0        0        0        1        0        0        0        0  \n",
       "5        0        0        0        0        0        0        0        0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_cat = df.actual.astype(\"category\")\n",
    "type_dummies = pd.get_dummies(type_cat)\n",
    "type_dummies = type_dummies.rename({\"INFJ\":\"is_infj\", \n",
    "                                    \"INFP\":\"is_infp\",\n",
    "                                    \"INTP\":\"is_intp\",\n",
    "                                    \"ENFJ\":\"is_enfj\",\n",
    "                                    \"ENFP\":\"is_enfp\",\n",
    "                                    \"INTJ\":\"is_intj\",\n",
    "                                    \"ENTP\":\"is_entp\",\n",
    "                                    \"ISTJ\":\"is_istj\",\n",
    "                                    \"ISFJ\":\"is_isfj\",\n",
    "                                    \"ESFP\":\"is_esfp\",\n",
    "                                    \"ISFP\":\"is_isfp\",\n",
    "                                    \"ISTP\":\"is_istp\",\n",
    "                                    \"ENTJ\":\"is_entj\",\n",
    "                                    \"ESFJ\":\"is_esfj\",\n",
    "                                    \"ESTJ\":\"is_estj\",\n",
    "                                    \"ESTP\":\"is_estp\",\n",
    "                                    \"I don't know\":\"is_unknown\"\n",
    "                                    }, axis=\"columns\")\n",
    "df = pd.concat([df,type_dummies], axis=1)\n",
    "type_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# James Pennebakers LIWC 2007\n",
    "\n",
    "[The Development of LIWC 2007](http://www.liwc.net/LIWC2007LanguageManual.pdf)\n",
    "\n",
    "[Personality Detection by Analysis of Twitter Profiles, Mehul Smriti Raje, Aakarsh Singh](https://books.google.se/books?id=s9IxDwAAQBAJ&lpg=PA675&ots=KVsRfV0yw4&dq=liwc%20jung&pg=PA670#v=onepage&q=liwc%20jung&f=false)\n",
    "\n",
    "[The Development of LIWC 2015](https://repositories.lib.utexas.edu/bitstream/handle/2152/31333/LIWC2015_LanguageManual.pdf)\n",
    "\n",
    "[Such Stuff as Dreams Are Made On; Dream Language, LIWC Norms and Personality Correlates](https://www.researchgate.net/publication/316109197_Such_Stuff_as_Dreams_Are_Made_On_Dream_Language_LIWC_Norms_Personality_Correlates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pickle.load(open(\"../../pickles/liwc_2007_cats_dict.pickle\",\"rb\"))\n",
    "words = pickle.load(open(\"../../pickles/liwc_2007_words_dict.pickle\",\"rb\"))\n",
    "    \n",
    "cats_names = []\n",
    "for key in cats.keys():\n",
    "    cats_names.append(cats[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punctuation_with_whitespace(original_string):\n",
    "   return re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", original_string) # todo: not perfect - leaves \"),\"\n",
    "\n",
    "\n",
    "def liwc_analysis_on_english_string(original_string, words):\n",
    "    \"\"\"\n",
    "    Takes a string and returns word frequencies according to (most of) LIWC 2007.\n",
    "    \n",
    "    :param original_string: string representing the input text with no transformations.\n",
    "    :param words: dictionary containing categories as keys with 0.0 as values plus \"WC\" = word count.\n",
    "    :return: dictionary containg LIWC 2007 categories minus the psychological summary variables. \n",
    "    \"\"\" \n",
    "    liwc = dict.fromkeys(cats_names, 0.0)\n",
    "    punct_token_text = separate_punctuation_with_whitespace(original_string)\n",
    "    liwc[\"WC\"] = len(punct_token_text.split()) # TODO: implement proper tokenization before word count\n",
    "\n",
    "    for word in words:\n",
    "        regex_word = re.sub(r\"\\*\",r\"\\w+\",word) # e.g. 'cousin*' in .dic file transformed into 'cousin\\w+'\n",
    "        word_patt = re.compile(regex_word)\n",
    "        \n",
    "        if word_patt.search(original_string):\n",
    "            matches = word_patt.findall(original_string)\n",
    "            #print(\"word: {}\".format(word))\n",
    "            #print(\"cat numbers: {}\".format(words[word]))\n",
    "            try:\n",
    "                for cat_no in words[word]:\n",
    "                    if liwc.get(cats[cat_no]):\n",
    "                        liwc[cats[cat_no]] += (len(matches) / liwc[\"WC\"])   \n",
    "                    else:\n",
    "                        liwc[cats[cat_no]] = (len(matches) / liwc[\"WC\"])\n",
    "            except TypeError as e:\n",
    "                print(\"TypeError with cat_no = {}\\n{}\".format(cat_no, e))\n",
    "    \n",
    "    return liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare storage for LIWC-results per row\n",
    "liwcresults = defaultdict(list)\n",
    "for cat in cats_names:\n",
    "    liwcresults[cat] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished counting LIWC words!\n"
     ]
    }
   ],
   "source": [
    "# Warning, takes time on an 1,8 GHz Intel Core i5 with 8GB memory\n",
    "for ix, row in df.iterrows():\n",
    "    print(\"Current ix: {}\".format(ix), end=\"\\r\")\n",
    "    liwc = liwc_analysis_on_english_string(row[\"text\"], words)\n",
    "    for cat in cats_names:\n",
    "        liwcresults[cat].append(liwc[cat])\n",
    "\n",
    "# Add LIWC-results from memory storage as Pandas Series objects to DataFrame\n",
    "for cat in cats_names:\n",
    "    s = pd.Series(liwcresults[cat])\n",
    "    df[cat] = s\n",
    "\n",
    "print(\"Finished counting LIWC words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all created columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url\n",
      "typealyzer\n",
      "actual\n",
      "e\n",
      "s\n",
      "t\n",
      "sntf_s\n",
      "sntf_n\n",
      "sntf_t\n",
      "sntf_f\n",
      "date\n",
      "text\n",
      "tokens\n",
      "domain\n",
      "lang\n",
      "datetime\n",
      "func\n",
      "att\n",
      "funcatt\n",
      "is_fe\n",
      "is_fi\n",
      "is_ne\n",
      "is_ni\n",
      "is_se\n",
      "is_si\n",
      "is_te\n",
      "is_ti\n",
      "is_enfj\n",
      "is_enfp\n",
      "is_entj\n",
      "is_entp\n",
      "is_esfj\n",
      "is_esfp\n",
      "is_estj\n",
      "is_estp\n",
      "is_infj\n",
      "is_infp\n",
      "is_intj\n",
      "is_intp\n",
      "is_isfj\n",
      "is_isfp\n",
      "is_istj\n",
      "is_istp\n",
      "time\n",
      "sad\n",
      "quant\n",
      "posemo\n",
      "achieve\n",
      "health\n",
      "home\n",
      "see\n",
      "shehe\n",
      "they\n",
      "death\n",
      "cogmech\n",
      "adverb\n",
      "humans\n",
      "discrep\n",
      "body\n",
      "relativ\n",
      "we\n",
      "number\n",
      "family\n",
      "you\n",
      "negate\n",
      "feel\n",
      "incl\n",
      "relig\n",
      "percept\n",
      "bio\n",
      "tentat\n",
      "preps\n",
      "inhib\n",
      "filler\n",
      "past\n",
      "ingest\n",
      "space\n",
      "leisure\n",
      "auxverb\n",
      "affect\n",
      "future\n",
      "negemo\n",
      "motion\n",
      "assent\n",
      "funct\n",
      "present\n",
      "conj\n",
      "i\n",
      "hear\n",
      "insight\n",
      "social\n",
      "certain\n",
      "nonfl\n",
      "work\n",
      "ppron\n",
      "excl\n",
      "anger\n",
      "swear\n",
      "friend\n",
      "cause\n",
      "money\n",
      "ipron\n",
      "anx\n",
      "verb\n",
      "article\n",
      "pronoun\n",
      "sexual\n",
      "actual_temp\n",
      "is_f\n",
      "is_n\n",
      "is_s\n",
      "is_t\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check transformations of myers-briggs types to its function parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>func</th>\n",
       "      <th>funcatt</th>\n",
       "      <th>att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fe</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ST</td>\n",
       "      <td>s</td>\n",
       "      <td>si</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>SF</td>\n",
       "      <td>s</td>\n",
       "      <td>si</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>SF</td>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>SF</td>\n",
       "      <td>s</td>\n",
       "      <td>si</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27083</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27084</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27085</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27086</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>SF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27087</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27088</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27089</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>SF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27090</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27091</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27092</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27093</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27094</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27095</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27096</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27097</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>SF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27098</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27099</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27100</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27101</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27102</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27103</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27104</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27105</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27106</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27107</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27108</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27109</th>\n",
       "      <td>INTP</td>\n",
       "      <td>NT</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27110</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27111</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>NT</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27112</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26469 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual actual_temp func funcatt att\n",
       "0       INFJ          NF    n      ni   i\n",
       "1       INFJ          NF    n      ni   i\n",
       "2       INFP          NF    f      fi   i\n",
       "3       INTP          NT    t      ti   i\n",
       "5       ENFJ          NF    f      fe   e\n",
       "6       ENFP          NF    n      ne   e\n",
       "7       INFP          NF    f      fi   i\n",
       "9       INTJ          NT    n      ni   i\n",
       "10      INFP          NF    f      fi   i\n",
       "13      INFP          NF    f      fi   i\n",
       "14      INFJ          NF    n      ni   i\n",
       "15      ENTP          NT    n      ne   e\n",
       "16      INTP          NT    t      ti   i\n",
       "17      INTP          NT    t      ti   i\n",
       "18      INTJ          NT    n      ni   i\n",
       "19      INTJ          NT    n      ni   i\n",
       "21      INFJ          NF    n      ni   i\n",
       "22      INTP          NT    t      ti   i\n",
       "23      ENTP          NT    n      ne   e\n",
       "24      ENTP          NT    n      ne   e\n",
       "25      INTP          NT    t      ti   i\n",
       "26      INTP          NT    t      ti   i\n",
       "27      ISTJ          ST    s      si   i\n",
       "28      ISFJ          SF    s      si   i\n",
       "29      ESFP          SF    s      se   e\n",
       "30      ISFJ          SF    s      si   i\n",
       "31      INTJ          NT    n      ni   i\n",
       "32      INFJ          NF    n      ni   i\n",
       "33      INTP          NT    t      ti   i\n",
       "34      INFP          NF    f      fi   i\n",
       "...      ...         ...  ...     ...  ..\n",
       "27083   INFP          NF    f      fi   i\n",
       "27084   INTJ          NT    n      ni   i\n",
       "27085   INTP          NT    t      ti   i\n",
       "27086   ISFP          SF    f      fi   i\n",
       "27087   INFJ          NF    n      ni   i\n",
       "27088   INTJ          NT    n      ni   i\n",
       "27089   ISFP          SF    f      fi   i\n",
       "27090   INFP          NF    f      fi   i\n",
       "27091   INTP          NT    t      ti   i\n",
       "27092   INFP          NF    f      fi   i\n",
       "27093   INTP          NT    t      ti   i\n",
       "27094   INTP          NT    t      ti   i\n",
       "27095   INFJ          NF    n      ni   i\n",
       "27096   INFJ          NF    n      ni   i\n",
       "27097   ISFP          SF    f      fi   i\n",
       "27098   INTJ          NT    n      ni   i\n",
       "27099   INTP          NT    t      ti   i\n",
       "27100   INFJ          NF    n      ni   i\n",
       "27101   INFJ          NF    n      ni   i\n",
       "27102   ENFP          NF    n      ne   e\n",
       "27103   ENFP          NF    n      ne   e\n",
       "27104   INTJ          NT    n      ni   i\n",
       "27105   INTP          NT    t      ti   i\n",
       "27106   INTJ          NT    n      ni   i\n",
       "27107   INTJ          NT    n      ni   i\n",
       "27108   INTJ          NT    n      ni   i\n",
       "27109   INTP          NT    t      ti   i\n",
       "27110   INTJ          NT    n      ni   i\n",
       "27111   INTJ          NT    n      ni   i\n",
       "27112   INFP          NF    f      fi   i\n",
       "\n",
       "[26469 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"actual\",\"actual_temp\",\"func\",\"funcatt\",\"att\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store enriched DataFrame to pickle and semicolon-separated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished storing data.\n"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")\n",
    "df.to_csv(\"../../data/processed/dataframe_survey_2018-01-23_enriched.csv\",sep=\";\")\n",
    "print(\"Finished storing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:memeticscience]",
   "language": "python",
   "name": "conda-env-memeticscience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
