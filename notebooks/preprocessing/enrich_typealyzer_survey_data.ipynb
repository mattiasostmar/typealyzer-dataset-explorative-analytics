{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If re-run\n",
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27113            INFJ\n",
       "27114            INTP\n",
       "27115            INTP\n",
       "27116            INFJ\n",
       "27117            INFP\n",
       "27118            INTJ\n",
       "27119            ENFP\n",
       "27120            INFJ\n",
       "27121            INFP\n",
       "27122            INFP\n",
       "27123            INFP\n",
       "27124            INFP\n",
       "27125            INFP\n",
       "27126            INFP\n",
       "27127            INFP\n",
       "27128            INFJ\n",
       "27129            INTP\n",
       "27130            INTP\n",
       "27131            INFP\n",
       "27132            ESTJ\n",
       "27133            INFP\n",
       "27134            INFJ\n",
       "27135            INTJ\n",
       "27136            INFP\n",
       "27137            INTJ\n",
       "27138            ESFP\n",
       "27139            ISTJ\n",
       "27140            INFJ\n",
       "27141            ENTP\n",
       "27142            ISFP\n",
       "             ...     \n",
       "27929            INFJ\n",
       "27930    I don't know\n",
       "27931            INFP\n",
       "27932            ENTJ\n",
       "27933            INTP\n",
       "27934            INFJ\n",
       "27935            ESTJ\n",
       "27936            INTP\n",
       "27937            INTJ\n",
       "27938            ISFP\n",
       "27939            ENFJ\n",
       "27940            INTP\n",
       "27941            INTP\n",
       "27942            ENTP\n",
       "27943            INTP\n",
       "27944            ISTJ\n",
       "27945            INFP\n",
       "27946            INFP\n",
       "27947            ESTJ\n",
       "27948            INFP\n",
       "27949            INFP\n",
       "27950            INFP\n",
       "27951            INFP\n",
       "27952            INFP\n",
       "27953            INTP\n",
       "27954            ISFP\n",
       "27955            INTJ\n",
       "27956            INTJ\n",
       "27957            INTJ\n",
       "27958            ENTP\n",
       "Name: actual, Length: 844, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"actual\"][pd.isnull(df.func)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0 # To ensure reproducible language detection results\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>typealyzer</th>\n",
       "      <th>actual</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>sntf_s</th>\n",
       "      <th>sntf_n</th>\n",
       "      <th>sntf_t</th>\n",
       "      <th>sntf_f</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>http://jaschmehl.wordpress.com</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>0.571364</td>\n",
       "      <td>0.432009</td>\n",
       "      <td>0.560149</td>\n",
       "      <td>0.246421</td>\n",
       "      <td>0.317213</td>\n",
       "      <td>0.235832</td>\n",
       "      <td>0.200534</td>\n",
       "      <td>20130220 05:02:44</td>\n",
       "      <td>Mind of a Mouse | Easily Startled, Probably Pa...</td>\n",
       "      <td>104</td>\n",
       "      <td>wordpress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18953</th>\n",
       "      <td>http://alanaisreading.tumblr.com</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.156309</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>0.374652</td>\n",
       "      <td>0.176104</td>\n",
       "      <td>0.713201</td>\n",
       "      <td>0.038251</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>20140814 04:08:08</td>\n",
       "      <td>Alana Is Reading Alana Is Reading American in ...</td>\n",
       "      <td>488</td>\n",
       "      <td>tumblr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url typealyzer        actual         e  \\\n",
       "637      http://jaschmehl.wordpress.com       ENTP  I don't know  0.571364   \n",
       "18953  http://alanaisreading.tumblr.com       INFP          INTJ  0.156309   \n",
       "\n",
       "              s         t    sntf_s    sntf_n    sntf_t    sntf_f  \\\n",
       "637    0.432009  0.560149  0.246421  0.317213  0.235832  0.200534   \n",
       "18953  0.170416  0.374652  0.176104  0.713201  0.038251  0.072443   \n",
       "\n",
       "                    date                                               text  \\\n",
       "637    20130220 05:02:44  Mind of a Mouse | Easily Startled, Probably Pa...   \n",
       "18953  20140814 04:08:08  Alana Is Reading Alana Is Reading American in ...   \n",
       "\n",
       "       tokens     domain  \n",
       "637       104  wordpress  \n",
       "18953     488     tumblr  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add language classification result to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current ix: 27958\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "en    27174\n",
       "fr       54\n",
       "da       40\n",
       "no       28\n",
       "de       28\n",
       "sv       27\n",
       "tl       16\n",
       "nl       15\n",
       "ca       15\n",
       "es       15\n",
       "ja       15\n",
       "af       14\n",
       "it       14\n",
       "ro       13\n",
       "et       13\n",
       "so       12\n",
       "cy       11\n",
       "id       10\n",
       "pt        9\n",
       "ko        9\n",
       "fi        7\n",
       "sl        5\n",
       "pl        5\n",
       "el        5\n",
       "lv        4\n",
       "bn        4\n",
       "lt        3\n",
       "ar        2\n",
       "sw        2\n",
       "sk        2\n",
       "uk        2\n",
       "sq        2\n",
       "tr        2\n",
       "vi        2\n",
       "cs        2\n",
       "hr        1\n",
       "ru        1\n",
       "ta        1\n",
       "mk        1\n",
       "hi        1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = []\n",
    "for ix, row in df.iterrows():\n",
    "    print(\"current ix: {}\".format(ix), end=\"\\r\")\n",
    "    try:\n",
    "        langs.append(detect(row[\"text\"]))\n",
    "    except:\n",
    "        print(\"ix: {} tokens: {}\\ntext{}\".format(ix, row[\"tokens\"], row[\"text\"]))\n",
    "df[\"lang\"] = pd.Series(langs)\n",
    "df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max datetime: 2018-01-22 05:01:47, Min datetime: 2012-08-28 08:08:11\n"
     ]
    }
   ],
   "source": [
    "df['datetime'] =  pd.to_datetime(df['date'], format='%Y%m%d %H:%M:%S')\n",
    "print(\"Max datetime: {}, Min datetime: {}\".format(df.datetime.max(), df.datetime.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carl Jungs functions and attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"t\":[\"ESTJ\",\"ENTJ\",\"ISTP\",\"INTP\"],\n",
    "    \"f\":[\"ESFJ\",\"ENFJ\",\"ISFP\",\"INFP\"],\n",
    "    \"n\":[\"ENTP\",\"ENFP\",\"INTJ\",\"INFJ\"],\n",
    "    \"s\":[\"ESTP\",\"ESFP\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "atts = {\n",
    "    \"e\":[\"ESTJ\",\"ENTJ\",\"ESFJ\",\"ENFJ\",\"ENTP\",\"ENFP\",\"ESTP\",\"ESFP\"],\n",
    "    \"i\":[\"ISTP\",\"INTP\",\"ISFP\",\"INFP\",\"INTJ\",\"INFJ\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "funcatts = {\n",
    "    \"te\":[\"ESTJ\",\"ENTJ\"],\n",
    "    \"ti\":[\"ISTP\",\"INTP\"],\n",
    "    \"fe\":[\"ESFJ\",\"ENFJ\"],\n",
    "    \"fi\":[\"ISFP\",\"INFP\"],\n",
    "    \"ne\":[\"ENTP\",\"ENFP\"],\n",
    "    \"ni\":[\"INTJ\",\"INFJ\"],\n",
    "    \"se\":[\"ESTP\",\"ESFP\"],\n",
    "    \"si\":[\"ISTJ\",\"ISFJ\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "funclist = []\n",
    "attlist = []\n",
    "funcattlist = []\n",
    "\n",
    "for ix, row in df.iterrows():\n",
    "    # functions\n",
    "    for key in funcs:\n",
    "        if row[\"actual\"] in funcs[key]:\n",
    "            funclist.append(key)\n",
    "    \n",
    "    # attitudes\n",
    "    for key in atts:\n",
    "        if row[\"actual\"] in atts[key]:\n",
    "            attlist.append(key) \n",
    "            \n",
    "    # functions with attitudes\n",
    "    for key in funcatts:\n",
    "        if row[\"actual\"] in funcatts[key]:\n",
    "            funcattlist.append(key) \n",
    "\n",
    "fs = pd.Series(funclist)\n",
    "df[\"func\"] = fs\n",
    "ats = pd.Series(attlist)\n",
    "df[\"att\"] = ats\n",
    "fas = pd.Series(funcattlist)\n",
    "df[\"funcatt\"] = fas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 1-hot categorical dummies for Jungian categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attitudes (E, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_e</th>\n",
       "      <th>is_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_e  is_i\n",
       "0     0     1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_cat = df.att.astype(\"category\")\n",
    "att_dummies = pd.get_dummies(att_cat)\n",
    "att_dummies = att_dummies.rename({\"e\":\"is_e\", \"i\":\"is_i\"}, axis=\"columns\")\n",
    "df = pd.concat([df,att_dummies], axis=1)\n",
    "att_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions (S, N, T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_f</th>\n",
       "      <th>is_n</th>\n",
       "      <th>is_s</th>\n",
       "      <th>is_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_f  is_n  is_s  is_t\n",
       "0     0     1     0     0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_cat = df.func.astype(\"category\")\n",
    "func_dummies = pd.get_dummies(func_cat)\n",
    "func_dummies = func_dummies.rename({\"f\":\"is_f\", \n",
    "                                    \"n\":\"is_n\", \n",
    "                                    \"s\":\"is_s\", \n",
    "                                    \"t\":\"is_t\"}, axis=\"columns\")\n",
    "df = pd.concat([df,func_dummies], axis=1)\n",
    "func_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions with attitudes (Si, Se, Ni, Ne, Ti, Te, Fi, Fe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fe</th>\n",
       "      <th>is_fi</th>\n",
       "      <th>is_ne</th>\n",
       "      <th>is_ni</th>\n",
       "      <th>is_se</th>\n",
       "      <th>is_si</th>\n",
       "      <th>is_te</th>\n",
       "      <th>is_ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fe  is_fi  is_ne  is_ni  is_se  is_si  is_te  is_ti\n",
       "0      0      0      0      1      0      0      0      0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcatt_cat = df.funcatt.astype(\"category\")\n",
    "funcatt_dummies = pd.get_dummies(funcatt_cat)\n",
    "funcatt_dummies = funcatt_dummies.rename({\"fe\":\"is_fe\", \n",
    "                                          \"fi\":\"is_fi\",\n",
    "                                          \"ne\":\"is_ne\",\n",
    "                                          \"ni\":\"is_ni\",\n",
    "                                          \"se\":\"is_se\",\n",
    "                                          \"si\":\"is_si\",\n",
    "                                          \"te\":\"is_te\",\n",
    "                                          \"ti\":\"is_ti\"\n",
    "                                            }, axis=\"columns\")\n",
    "df = pd.concat([df,funcatt_dummies], axis=1)\n",
    "funcatt_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jung-Meyers types (ENTJ, ISFP etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_enfj</th>\n",
       "      <th>is_enfp</th>\n",
       "      <th>is_entj</th>\n",
       "      <th>is_entp</th>\n",
       "      <th>is_esfj</th>\n",
       "      <th>is_esfp</th>\n",
       "      <th>is_estj</th>\n",
       "      <th>is_estp</th>\n",
       "      <th>is_unknown</th>\n",
       "      <th>is_infj</th>\n",
       "      <th>is_infp</th>\n",
       "      <th>is_intj</th>\n",
       "      <th>is_intp</th>\n",
       "      <th>is_isfj</th>\n",
       "      <th>is_isfp</th>\n",
       "      <th>is_istj</th>\n",
       "      <th>is_istp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_enfj  is_enfp  is_entj  is_entp  is_esfj  is_esfp  is_estj  is_estp  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   is_unknown  is_infj  is_infp  is_intj  is_intp  is_isfj  is_isfp  is_istj  \\\n",
       "0           0        1        0        0        0        0        0        0   \n",
       "\n",
       "   is_istp  \n",
       "0        0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_cat = df.actual.astype(\"category\")\n",
    "type_dummies = pd.get_dummies(type_cat)\n",
    "type_dummies = type_dummies.rename({\"INFJ\":\"is_infj\", \n",
    "                                    \"INFP\":\"is_infp\",\n",
    "                                    \"INTP\":\"is_intp\",\n",
    "                                    \"ENFJ\":\"is_enfj\",\n",
    "                                    \"ENFP\":\"is_enfp\",\n",
    "                                    \"INTJ\":\"is_intj\",\n",
    "                                    \"ENTP\":\"is_entp\",\n",
    "                                    \"ISTJ\":\"is_istj\",\n",
    "                                    \"ISFJ\":\"is_isfj\",\n",
    "                                    \"ESFP\":\"is_esfp\",\n",
    "                                    \"ISFP\":\"is_isfp\",\n",
    "                                    \"ISTP\":\"is_istp\",\n",
    "                                    \"ENTJ\":\"is_entj\",\n",
    "                                    \"ESFJ\":\"is_esfj\",\n",
    "                                    \"ESTJ\":\"is_estj\",\n",
    "                                    \"ESTP\":\"is_estp\",\n",
    "                                    \"I don't know\":\"is_unknown\"\n",
    "                                    }, axis=\"columns\")\n",
    "df = pd.concat([df,type_dummies], axis=1)\n",
    "type_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# James Pennebakers LIWC 2007\n",
    "\n",
    "[The Development of LIWC 2007](http://www.liwc.net/LIWC2007LanguageManual.pdf)\n",
    "\n",
    "[Personality Detection by Analysis of Twitter Profiles, Mehul Smriti Raje, Aakarsh Singh](https://books.google.se/books?id=s9IxDwAAQBAJ&lpg=PA675&ots=KVsRfV0yw4&dq=liwc%20jung&pg=PA670#v=onepage&q=liwc%20jung&f=false)\n",
    "\n",
    "[The Development of LIWC 2015](https://repositories.lib.utexas.edu/bitstream/handle/2152/31333/LIWC2015_LanguageManual.pdf)\n",
    "\n",
    "[Such Stuff as Dreams Are Made On; Dream Language, LIWC Norms and Personality Correlates](https://www.researchgate.net/publication/316109197_Such_Stuff_as_Dreams_Are_Made_On_Dream_Language_LIWC_Norms_Personality_Correlates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pickle.load(open(\"../../pickles/liwc_2007_cats_dict.pickle\",\"rb\"))\n",
    "words = pickle.load(open(\"../../pickles/liwc_2007_words_dict.pickle\",\"rb\"))\n",
    "    \n",
    "cats_names = []\n",
    "for key in cats.keys():\n",
    "    cats_names.append(cats[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punctuation_with_whitespace(original_string):\n",
    "   return re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", original_string) # todo: not perfect - leaves \"),\"\n",
    "\n",
    "\n",
    "def liwc_analysis_on_english_string(original_string, words):\n",
    "    \"\"\"\n",
    "    Takes a string and returns word frequencies according to (most of) LIWC 2007.\n",
    "    \n",
    "    :param original_string: string representing the input text with no transformations.\n",
    "    :param words: dictionary containing categories as keys with 0.0 as values plus \"WC\" = word count.\n",
    "    :return: dictionary containg LIWC 2007 categories minus the psychological summary variables. \n",
    "    \"\"\" \n",
    "    liwc = dict.fromkeys(cats_names, 0.0)\n",
    "    punct_token_text = separate_punctuation_with_whitespace(original_string)\n",
    "    liwc[\"WC\"] = len(punct_token_text.split()) # TODO: implement proper tokenization before word count\n",
    "\n",
    "    for word in words:\n",
    "        regex_word = re.sub(r\"\\*\",r\"\\w+\",word) # e.g. 'cousin*' in .dic file transformed into 'cousin\\w+'\n",
    "        word_patt = re.compile(regex_word)\n",
    "        \n",
    "        if word_patt.search(original_string):\n",
    "            matches = word_patt.findall(original_string)\n",
    "            #print(\"word: {}\".format(word))\n",
    "            #print(\"cat numbers: {}\".format(words[word]))\n",
    "            try:\n",
    "                for cat_no in words[word]:\n",
    "                    if liwc.get(cats[cat_no]):\n",
    "                        liwc[cats[cat_no]] += (len(matches) / liwc[\"WC\"])   \n",
    "                    else:\n",
    "                        liwc[cats[cat_no]] = (len(matches) / liwc[\"WC\"])\n",
    "            except TypeError as e:\n",
    "                print(\"TypeError with cat_no = {}\\n{}\".format(cat_no, e))\n",
    "    \n",
    "    return liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare storage for LIWC-results per row\n",
    "liwcresults = defaultdict(list)\n",
    "for cat in cats_names:\n",
    "    liwcresults[cat] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished counting LIWC words!\n"
     ]
    }
   ],
   "source": [
    "# Warning, takes time on an 1,8 GHz Intel Core i5 with 8GB memory\n",
    "for ix, row in df.iterrows():\n",
    "    print(\"Current ix: {}\".format(ix), end=\"\\r\")\n",
    "    liwc = liwc_analysis_on_english_string(row[\"text\"], words)\n",
    "    for cat in cats_names:\n",
    "        liwcresults[cat].append(liwc[cat])\n",
    "\n",
    "# Add LIWC-results from memory storage as Pandas Series objects to DataFrame\n",
    "for cat in cats_names:\n",
    "    s = pd.Series(liwcresults[cat])\n",
    "    df[cat] = s\n",
    "\n",
    "print(\"Finished counting LIWC words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final check of all created columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url\n",
      "typealyzer\n",
      "actual\n",
      "e\n",
      "s\n",
      "t\n",
      "sntf_s\n",
      "sntf_n\n",
      "sntf_t\n",
      "sntf_f\n",
      "date\n",
      "text\n",
      "tokens\n",
      "domain\n",
      "lang\n",
      "datetime\n",
      "func\n",
      "att\n",
      "funcatt\n",
      "is_e\n",
      "is_i\n",
      "is_f\n",
      "is_n\n",
      "is_s\n",
      "is_t\n",
      "is_fe\n",
      "is_fi\n",
      "is_ne\n",
      "is_ni\n",
      "is_se\n",
      "is_si\n",
      "is_te\n",
      "is_ti\n",
      "is_enfj\n",
      "is_enfp\n",
      "is_entj\n",
      "is_entp\n",
      "is_esfj\n",
      "is_esfp\n",
      "is_estj\n",
      "is_estp\n",
      "is_unknown\n",
      "is_infj\n",
      "is_infp\n",
      "is_intj\n",
      "is_intp\n",
      "is_isfj\n",
      "is_isfp\n",
      "is_istj\n",
      "is_istp\n",
      "quant\n",
      "anx\n",
      "they\n",
      "certain\n",
      "i\n",
      "money\n",
      "past\n",
      "funct\n",
      "insight\n",
      "shehe\n",
      "feel\n",
      "relig\n",
      "preps\n",
      "ipron\n",
      "nonfl\n",
      "incl\n",
      "cogmech\n",
      "motion\n",
      "health\n",
      "friend\n",
      "sexual\n",
      "adverb\n",
      "leisure\n",
      "discrep\n",
      "cause\n",
      "negemo\n",
      "present\n",
      "auxverb\n",
      "space\n",
      "filler\n",
      "future\n",
      "negate\n",
      "relativ\n",
      "home\n",
      "excl\n",
      "anger\n",
      "hear\n",
      "pronoun\n",
      "death\n",
      "article\n",
      "inhib\n",
      "family\n",
      "affect\n",
      "we\n",
      "achieve\n",
      "swear\n",
      "ingest\n",
      "body\n",
      "verb\n",
      "humans\n",
      "sad\n",
      "tentat\n",
      "work\n",
      "ppron\n",
      "posemo\n",
      "social\n",
      "assent\n",
      "bio\n",
      "conj\n",
      "see\n",
      "percept\n",
      "time\n",
      "you\n",
      "number\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store enriched DataFrame to pickle and semicolon-separated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished storing data.\n"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")\n",
    "df.to_csv(\"../../data/processed/dataframe_survey_2018-01-23_enriched.csv\",sep=\";\")\n",
    "print(\"Finished storing data.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:memeticscience]",
   "language": "python",
   "name": "conda-env-memeticscience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
