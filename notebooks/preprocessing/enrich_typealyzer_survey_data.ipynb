{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26469 entries, 0 to 27112\n",
      "Columns: 112 entries, url to is_t\n",
      "dtypes: datetime64[ns](1), float64(71), int64(1), object(11), uint8(28)\n",
      "memory usage: 17.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# If re-run\n",
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0 # To ensure reproducible language detection results\n",
    "import string\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25438 entries, 1 to 27771\n",
      "Data columns (total 15 columns):\n",
      "url           25438 non-null object\n",
      "typealyzer    25438 non-null object\n",
      "actual        25438 non-null object\n",
      "e             25438 non-null float64\n",
      "s             25438 non-null float64\n",
      "t             25438 non-null float64\n",
      "sntf_s        25438 non-null float64\n",
      "sntf_n        25438 non-null float64\n",
      "sntf_t        25438 non-null float64\n",
      "sntf_f        25438 non-null float64\n",
      "date          25438 non-null object\n",
      "text          25438 non-null object\n",
      "tokens        25438 non-null int64\n",
      "domain        25438 non-null object\n",
      "lang          23420 non-null object\n",
      "dtypes: float64(7), int64(1), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_cleaned.pickle\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max datetime: 2018-01-22 02:01:03, Min datetime: 2012-08-28 08:08:11\n"
     ]
    }
   ],
   "source": [
    "df['datetime'] =  pd.to_datetime(df['date'], format='%Y%m%d %H:%M:%S')\n",
    "print(\"Max datetime: {}, Min datetime: {}\".format(df.datetime.max(), df.datetime.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carl Jungs functions and attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25438"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"t\":[\"ESTJ\",\"ENTJ\",\"ISTP\",\"INTP\"],\n",
    "    \"f\":[\"ESFJ\",\"ENFJ\",\"ISFP\",\"INFP\"],\n",
    "    \"n\":[\"ENTP\",\"ENFP\",\"INTJ\",\"INFJ\"],\n",
    "    \"s\":[\"ESTP\",\"ESFP\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "atts = {\n",
    "    \"e\":[\"ESTJ\",\"ENTJ\",\"ESFJ\",\"ENFJ\",\"ENTP\",\"ENFP\",\"ESTP\",\"ESFP\"],\n",
    "    \"i\":[\"ISTP\",\"INTP\",\"ISFP\",\"INFP\",\"INTJ\",\"INFJ\",\"ISTJ\",\"ISFJ\"]\n",
    "}\n",
    "\n",
    "funcatts = {\n",
    "    \"te\":[\"ESTJ\",\"ENTJ\"],\n",
    "    \"ti\":[\"ISTP\",\"INTP\"],\n",
    "    \"fe\":[\"ESFJ\",\"ENFJ\"],\n",
    "    \"fi\":[\"ISFP\",\"INFP\"],\n",
    "    \"ne\":[\"ENTP\",\"ENFP\"],\n",
    "    \"ni\":[\"INTJ\",\"INFJ\"],\n",
    "    \"se\":[\"ESTP\",\"ESFP\"],\n",
    "    \"si\":[\"ISTJ\",\"ISFJ\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df): 25438\n",
      "len(fs): 25438\n",
      "len(ats): 25438\n",
      "len(fas): 25438\n"
     ]
    }
   ],
   "source": [
    "funclist = []\n",
    "attlist = []\n",
    "funcattlist = []\n",
    "\n",
    "for ix, row in df.iterrows():\n",
    "    #print(ix, end=\"\\r\")\n",
    "    # functions\n",
    "    key_found = None\n",
    "    for key_no, key in enumerate(funcs):\n",
    "        if row[\"actual\"] in funcs[key]:\n",
    "            funclist.append(key)\n",
    "            key_found = 1\n",
    "        elif key_no == 3 and not key_found:\n",
    "            funclist.append(np.nan)\n",
    "    \n",
    "    # attitudes\n",
    "    key_found = None\n",
    "    for key_no, key in enumerate(atts):\n",
    "        if row[\"actual\"] in atts[key]:\n",
    "            attlist.append(key)\n",
    "            key_found = 1\n",
    "        elif key_no == 1 and not key_found:\n",
    "            attlist.append(np.nan)\n",
    "            \n",
    "    # functions with attitudes\n",
    "    key_found = None\n",
    "    for key_no, key in enumerate(funcatts):\n",
    "        if row[\"actual\"] in funcatts[key]:\n",
    "            funcattlist.append(key)\n",
    "            key_found = 1\n",
    "        elif key_no == 7 and not key_found:\n",
    "            funcattlist.append(np.nan)\n",
    "        \n",
    "\n",
    "fs = pd.Series(funclist)\n",
    "df[\"func\"] = fs\n",
    "ats = pd.Series(attlist)\n",
    "df[\"att\"] = ats\n",
    "fas = pd.Series(funcattlist)\n",
    "df[\"funcatt\"] = fas\n",
    "print(\"len(df): {}\".format(len(df)))\n",
    "print(\"len(fs): {}\".format(len(fs)))\n",
    "print(\"len(ats): {}\".format(len(ats)))\n",
    "print(\"len(fas): {}\".format(len(fas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop all \"I don't know\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[[\"actual\",\"func\"]][pd.isnull(df.func)]) # how many \"I don't know\" responses do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22919"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add derived two-letter type, \"temperament\" to samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mos/anaconda3/envs/memeticscience/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Add derived two-letter type. \"temperament\"\n",
    "all_two_letters = df.actual.str.extract(\"\\w(\\w\\w)\\w\")\n",
    "all_two_letters = all_two_letters.replace(\"no\",np.nan)\n",
    "all_two_letters = all_two_letters.str.lower()\n",
    "df[\"actual_temp\"] = all_two_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 1-hot categorical dummies for Jungian categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attitudes (E, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_e</th>\n",
       "      <th>is_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_e  is_i\n",
       "1      0     1\n",
       "2      0     1\n",
       "3      1     0\n",
       "5      0     1\n",
       "10     0     1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_cat = df.att.astype(\"category\")\n",
    "att_dummies = pd.get_dummies(att_cat)\n",
    "att_dummies = att_dummies.rename({\"e\":\"is_e\", \"i\":\"is_i\"}, axis=\"columns\")\n",
    "df = pd.concat([df,att_dummies], axis=1)\n",
    "att_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions (S, N, T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_f</th>\n",
       "      <th>is_n</th>\n",
       "      <th>is_s</th>\n",
       "      <th>is_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_f  is_n  is_s  is_t\n",
       "1      1     0     0     0\n",
       "2      0     0     0     1\n",
       "3      1     0     0     0\n",
       "5      1     0     0     0\n",
       "10     0     0     0     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_cat = df.func.astype(\"category\")\n",
    "func_dummies = pd.get_dummies(func_cat)\n",
    "func_dummies = func_dummies.rename({\"f\":\"is_f\", \n",
    "                                    \"n\":\"is_n\", \n",
    "                                    \"s\":\"is_s\", \n",
    "                                    \"t\":\"is_t\"}, axis=\"columns\")\n",
    "df = pd.concat([df,func_dummies], axis=1)\n",
    "func_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions with attitudes (Si, Se, Ni, Ne, Ti, Te, Fi, Fe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fe</th>\n",
       "      <th>is_fi</th>\n",
       "      <th>is_ne</th>\n",
       "      <th>is_ni</th>\n",
       "      <th>is_se</th>\n",
       "      <th>is_si</th>\n",
       "      <th>is_te</th>\n",
       "      <th>is_ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_fe  is_fi  is_ne  is_ni  is_se  is_si  is_te  is_ti\n",
       "1       0      1      0      0      0      0      0      0\n",
       "2       0      0      0      0      0      0      0      1\n",
       "3       1      0      0      0      0      0      0      0\n",
       "5       0      1      0      0      0      0      0      0\n",
       "10      0      0      0      0      0      0      0      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcatt_cat = df.funcatt.astype(\"category\")\n",
    "funcatt_dummies = pd.get_dummies(funcatt_cat)\n",
    "funcatt_dummies = funcatt_dummies.rename({\"fe\":\"is_fe\", \n",
    "                                          \"fi\":\"is_fi\",\n",
    "                                          \"ne\":\"is_ne\",\n",
    "                                          \"ni\":\"is_ni\",\n",
    "                                          \"se\":\"is_se\",\n",
    "                                          \"si\":\"is_si\",\n",
    "                                          \"te\":\"is_te\",\n",
    "                                          \"ti\":\"is_ti\"\n",
    "                                            }, axis=\"columns\")\n",
    "df = pd.concat([df,funcatt_dummies], axis=1)\n",
    "funcatt_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jung-Meyers types (ENTJ, ISFP etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_enfj</th>\n",
       "      <th>is_enfp</th>\n",
       "      <th>is_entj</th>\n",
       "      <th>is_entp</th>\n",
       "      <th>is_esfj</th>\n",
       "      <th>is_esfp</th>\n",
       "      <th>is_estj</th>\n",
       "      <th>is_estp</th>\n",
       "      <th>is_unknown</th>\n",
       "      <th>is_infj</th>\n",
       "      <th>is_infp</th>\n",
       "      <th>is_intj</th>\n",
       "      <th>is_intp</th>\n",
       "      <th>is_isfj</th>\n",
       "      <th>is_isfp</th>\n",
       "      <th>is_istj</th>\n",
       "      <th>is_istp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_enfj  is_enfp  is_entj  is_entp  is_esfj  is_esfp  is_estj  is_estp  \\\n",
       "1         0        0        0        0        0        0        0        0   \n",
       "2         0        0        0        0        0        0        0        0   \n",
       "3         0        0        0        0        0        0        0        0   \n",
       "5         1        0        0        0        0        0        0        0   \n",
       "10        0        0        0        0        0        0        0        0   \n",
       "\n",
       "    is_unknown  is_infj  is_infp  is_intj  is_intp  is_isfj  is_isfp  is_istj  \\\n",
       "1            0        1        0        0        0        0        0        0   \n",
       "2            0        0        1        0        0        0        0        0   \n",
       "3            0        0        0        0        1        0        0        0   \n",
       "5            0        0        0        0        0        0        0        0   \n",
       "10           0        0        1        0        0        0        0        0   \n",
       "\n",
       "    is_istp  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "5         0  \n",
       "10        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_cat = df.actual.astype(\"category\")\n",
    "type_dummies = pd.get_dummies(type_cat)\n",
    "type_dummies = type_dummies.rename({\"INFJ\":\"is_infj\", \n",
    "                                    \"INFP\":\"is_infp\",\n",
    "                                    \"INTP\":\"is_intp\",\n",
    "                                    \"ENFJ\":\"is_enfj\",\n",
    "                                    \"ENFP\":\"is_enfp\",\n",
    "                                    \"INTJ\":\"is_intj\",\n",
    "                                    \"ENTP\":\"is_entp\",\n",
    "                                    \"ISTJ\":\"is_istj\",\n",
    "                                    \"ISFJ\":\"is_isfj\",\n",
    "                                    \"ESFP\":\"is_esfp\",\n",
    "                                    \"ISFP\":\"is_isfp\",\n",
    "                                    \"ISTP\":\"is_istp\",\n",
    "                                    \"ENTJ\":\"is_entj\",\n",
    "                                    \"ESFJ\":\"is_esfj\",\n",
    "                                    \"ESTJ\":\"is_estj\",\n",
    "                                    \"ESTP\":\"is_estp\",\n",
    "                                    \"I don't know\":\"is_unknown\"\n",
    "                                    }, axis=\"columns\")\n",
    "df = pd.concat([df,type_dummies], axis=1)\n",
    "type_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# James Pennebakers LIWC 2007\n",
    "\n",
    "[The Development of LIWC 2007](http://www.liwc.net/LIWC2007LanguageManual.pdf)\n",
    "\n",
    "[Personality Detection by Analysis of Twitter Profiles, Mehul Smriti Raje, Aakarsh Singh](https://books.google.se/books?id=s9IxDwAAQBAJ&lpg=PA675&ots=KVsRfV0yw4&dq=liwc%20jung&pg=PA670#v=onepage&q=liwc%20jung&f=false)\n",
    "\n",
    "[The Development of LIWC 2015](https://repositories.lib.utexas.edu/bitstream/handle/2152/31333/LIWC2015_LanguageManual.pdf)\n",
    "\n",
    "[Such Stuff as Dreams Are Made On; Dream Language, LIWC Norms and Personality Correlates](https://www.researchgate.net/publication/316109197_Such_Stuff_as_Dreams_Are_Made_On_Dream_Language_LIWC_Norms_Personality_Correlates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pickle.load(open(\"../../pickles/liwc_2007_cats_dict.pickle\",\"rb\"))\n",
    "words = pickle.load(open(\"../../pickles/liwc_2007_words_dict.pickle\",\"rb\"))\n",
    "    \n",
    "cats_names = []\n",
    "for key in cats.keys():\n",
    "    cats_names.append(cats[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punctuation_with_whitespace(original_string):\n",
    "   return re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", original_string) # todo: not perfect - leaves \"),\"\n",
    "\n",
    "\n",
    "def liwc_analysis_on_english_string(original_string, words):\n",
    "    \"\"\"\n",
    "    Takes a string and returns word frequencies according to (most of) LIWC 2007.\n",
    "    \n",
    "    :param original_string: string representing the input text with no transformations.\n",
    "    :param words: dictionary containing categories as keys with 0.0 as values plus \"WC\" = word count.\n",
    "    :return: dictionary containg LIWC 2007 categories minus the psychological summary variables. \n",
    "    \"\"\" \n",
    "    liwc = dict.fromkeys(cats_names, 0.0)\n",
    "    punct_token_text = separate_punctuation_with_whitespace(original_string)\n",
    "    liwc[\"WC\"] = len(punct_token_text.split()) # TODO: implement proper tokenization before word count\n",
    "\n",
    "    for word in words:\n",
    "        regex_word = re.sub(r\"\\*\",r\"\\w+\",word) # e.g. 'cousin*' in .dic file transformed into 'cousin\\w+'\n",
    "        word_patt = re.compile(regex_word)\n",
    "        \n",
    "        if word_patt.search(original_string):\n",
    "            matches = word_patt.findall(original_string)\n",
    "            #print(\"word: {}\".format(word))\n",
    "            #print(\"cat numbers: {}\".format(words[word]))\n",
    "            try:\n",
    "                for cat_no in words[word]:\n",
    "                    if liwc.get(cats[cat_no]):\n",
    "                        liwc[cats[cat_no]] += (len(matches) / liwc[\"WC\"])   \n",
    "                    else:\n",
    "                        liwc[cats[cat_no]] = (len(matches) / liwc[\"WC\"])\n",
    "            except TypeError as e:\n",
    "                print(\"TypeError with cat_no = {}\\n{}\".format(cat_no, e))\n",
    "    \n",
    "    return liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare storage for LIWC-results per row\n",
    "liwcresults = defaultdict(list)\n",
    "for cat in cats_names:\n",
    "    liwcresults[cat] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished counting LIWC words!\n"
     ]
    }
   ],
   "source": [
    "# Warning, takes time on an 1,8 GHz Intel Core i5 with 8GB memory\n",
    "for ix, row in df.iterrows():\n",
    "    print(\"Current ix: {}\".format(ix), end=\"\\r\")\n",
    "    liwc = liwc_analysis_on_english_string(row[\"text\"], words)\n",
    "    for cat in cats_names:\n",
    "        liwcresults[cat].append(liwc[cat])\n",
    "\n",
    "# Add LIWC-results from memory storage as Pandas Series objects to DataFrame\n",
    "for cat in cats_names:\n",
    "    s = pd.Series(liwcresults[cat])\n",
    "    df[cat] = s\n",
    "\n",
    "print(\"Finished counting LIWC words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all created columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url\n",
      "typealyzer\n",
      "actual\n",
      "e\n",
      "s\n",
      "t\n",
      "sntf_s\n",
      "sntf_n\n",
      "sntf_t\n",
      "sntf_f\n",
      "date\n",
      "text\n",
      "tokens\n",
      "domain\n",
      "lang\n",
      "datetime\n",
      "func\n",
      "att\n",
      "funcatt\n",
      "actual_temp\n",
      "is_e\n",
      "is_i\n",
      "is_f\n",
      "is_n\n",
      "is_s\n",
      "is_t\n",
      "is_fe\n",
      "is_fi\n",
      "is_ne\n",
      "is_ni\n",
      "is_se\n",
      "is_si\n",
      "is_te\n",
      "is_ti\n",
      "is_enfj\n",
      "is_enfp\n",
      "is_entj\n",
      "is_entp\n",
      "is_esfj\n",
      "is_esfp\n",
      "is_estj\n",
      "is_estp\n",
      "is_unknown\n",
      "is_infj\n",
      "is_infp\n",
      "is_intj\n",
      "is_intp\n",
      "is_isfj\n",
      "is_isfp\n",
      "is_istj\n",
      "is_istp\n",
      "negate\n",
      "ppron\n",
      "nonfl\n",
      "i\n",
      "relativ\n",
      "percept\n",
      "quant\n",
      "affect\n",
      "shehe\n",
      "achieve\n",
      "bio\n",
      "leisure\n",
      "conj\n",
      "motion\n",
      "posemo\n",
      "adverb\n",
      "home\n",
      "future\n",
      "negemo\n",
      "number\n",
      "inhib\n",
      "humans\n",
      "pronoun\n",
      "excl\n",
      "space\n",
      "tentat\n",
      "see\n",
      "past\n",
      "anx\n",
      "family\n",
      "present\n",
      "health\n",
      "verb\n",
      "certain\n",
      "anger\n",
      "preps\n",
      "swear\n",
      "ingest\n",
      "discrep\n",
      "friend\n",
      "relig\n",
      "time\n",
      "cause\n",
      "article\n",
      "body\n",
      "social\n",
      "assent\n",
      "work\n",
      "sexual\n",
      "insight\n",
      "ipron\n",
      "filler\n",
      "death\n",
      "funct\n",
      "sad\n",
      "you\n",
      "cogmech\n",
      "auxverb\n",
      "they\n",
      "incl\n",
      "money\n",
      "feel\n",
      "we\n",
      "hear\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check transformations of myers-briggs types to its function parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>actual_temp</th>\n",
       "      <th>func</th>\n",
       "      <th>funcatt</th>\n",
       "      <th>att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>f</td>\n",
       "      <td>fe</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I don't know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>s</td>\n",
       "      <td>si</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>f</td>\n",
       "      <td>fe</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>nt</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I don't know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>n</td>\n",
       "      <td>ne</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>sf</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>INTP</td>\n",
       "      <td>nt</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>nt</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>nt</td>\n",
       "      <td>f</td>\n",
       "      <td>fi</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>nf</td>\n",
       "      <td>t</td>\n",
       "      <td>ti</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          actual actual_temp func funcatt att\n",
       "1           INFJ          nf    f      fi   i\n",
       "2           INFP          nf    t      ti   i\n",
       "3           INTP          nt    f      fe   e\n",
       "5           ENFJ          nf    f      fi   i\n",
       "10          INFP          nf    t      ti   i\n",
       "11  I don't know         NaN    n      ni   i\n",
       "14          INFJ          nf    t      ti   i\n",
       "15          ENTP          nt    f      fi   i\n",
       "16          INTP          nt    s      si   i\n",
       "17          INTP          nt    f      fe   e\n",
       "18          INTJ          nt    n      ni   i\n",
       "20  I don't know         NaN    n      ni   i\n",
       "21          INFJ          nf    t      ti   i\n",
       "25          INTP          nt    n      ne   e\n",
       "34          INFP          nf    t      ti   i\n",
       "35          ISFJ          sf    n      ni   i\n",
       "36          ENFJ          nf    n      ni   i\n",
       "37          INFJ          nf    f      fi   i\n",
       "38          INFJ          nf    s      se   e\n",
       "39          INFJ          nf    t      ti   i\n",
       "41          INTP          nt    n      ni   i\n",
       "43          INFP          nf    f      fi   i\n",
       "44          INTJ          nt    n      ni   i\n",
       "45          INTJ          nt    f      fi   i\n",
       "46          ENFP          nf    t      ti   i"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"actual\",\"actual_temp\",\"func\",\"funcatt\",\"att\"]].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store enriched DataFrame to pickle and semicolon-separated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished storing data.\n"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")\n",
    "df.to_csv(\"../../data/processed/dataframe_survey_2018-01-23_enriched.csv\",sep=\";\")\n",
    "print(\"Finished storing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../pickles/dataframe_survey_2018-01-23_enriched.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare simplified dataset (no NaNs, english blogs only) for public release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df[df.lang == \"en\"]\n",
    "en_blogs_df = en_df[(en_df.domain == \"wordpress\") | (en_df.domain == \"blogspot\") | (en_df.domain == \"tumblr\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22588 entries, 1 to 25437\n",
      "Columns: 115 entries, url to hear\n",
      "dtypes: datetime64[ns](1), float64(71), int64(1), object(11), uint8(31)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "en_blogs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22588"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blogs_funcs_df = en_blogs_df[[\"text\", \"func\", \"funcatt\"]]\n",
    "en_blogs_funcs_df.columns = [\"text\", \"base_function\", \"directed_function\"]\n",
    "len(en_blogs_funcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_blogs_funcs_df.to_csv(\"../../data/processed/blog_texts_and_cognitive_function.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:memeticscience]",
   "language": "python",
   "name": "conda-env-memeticscience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
